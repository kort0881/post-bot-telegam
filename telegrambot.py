import os
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional

import requests
import feedparser
from aiogram import Bot
from aiogram.client.bot import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.types import FSInputFile

from openai import OpenAI

# ---------------- CONFIG ----------------

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
if not all([OPENAI_API_KEY, TELEGRAM_BOT_TOKEN, CHANNEL_ID]):
    raise ValueError("‚ùå –ù–µ –≤—Å–µ ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ OPENAI_API_KEY, TELEGRAM_BOT_TOKEN, CHANNEL_ID")

print("DEBUG OPENAI KEY LEN:", len(OPENAI_API_KEY) if OPENAI_API_KEY else 0)

bot = Bot(
    token=TELEGRAM_BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML),
)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    )
}

POSTED_FILE = "posted_articles.json"
RETENTION_DAYS = 7

# ---------------- KEYWORDS ----------------

STRONG_KEYWORDS = [
    "vpn", "–≤–ø–Ω", "–ø—Ä–æ–∫—Å–∏", "proxy", "tor", "shadowsocks",
    "wireguard", "openvpn", "ikev2",
    "–æ–±—Ö–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫", "–æ–±—Ö–æ–¥ —Ü–µ–Ω–∑—É—Ä—ã", "–∞–Ω–æ–Ω–∏–º–Ω–æ—Å—Ç—å",
    "—Ä–æ—Å–∫–æ–º–Ω–∞–¥–∑–æ—Ä", "—Ä–∫–Ω",
    "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Ü–µ–Ω–∑—É—Ä–∞", "—Ü–µ–Ω–∑—É—Ä–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ",
    "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Å–∞–π—Ç–æ–≤", "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Ä–µ—Å—É—Ä—Å–∞",
    "—Ä–µ–µ—Å—Ç—Ä –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã—Ö —Å–∞–π—Ç–æ–≤", "–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞",
    "—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç—Ä–∞—Ñ–∏–∫–∞", "dpi", "deep packet inspection",
    "—Ç–µ–ª–µ–≥—Ä–∞–º", "telegram",
    "whatsapp", "signal", "viber",
    "messenger", "–º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä",
    "–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "–ø–∞—Ç—á –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
    "–∞–Ω—Ç–∏–≤–∏—Ä—É—Å", "firewall", "—Ñ–∞–µ—Ä–≤–æ–ª",
    "–±—Ä–∞—É–∑–µ—Ä", "–±—Ä–∞—É–∑–µ—Ä tor",
    "–∫–ª–∏–µ–Ω—Ç vpn", "vpn-–∫–ª–∏–µ–Ω—Ç",
    "–º–∏–Ω—Ü–∏—Ñ—Ä—ã", "–º–∏–Ω—Ü–∏—Ñ—Ä—ã —Ä—Ñ",
    "–±–µ–ª—ã–µ —Å–ø–∏—Å–∫–∏", "–±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫",
    "—Ä–æ—Å–∫–æ–º—Å–≤–æ–±–æ–¥–∞", "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞", "–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ",
]

SOFT_KEYWORDS = [
    "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø–∫", "desktop-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "—É—Ç–∏–ª–∏—Ç–∞ –¥–ª—è windows",
    "–ø—Ä–æ–≥—Ä–∞–º–º–∞ –¥–ª—è macos", "open source",
    "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–Ω–µ–π—Ä–æ—Å–µ—Ç—å", "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏",
    "ai", "machine learning",
    "–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å",
    "–∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ", "privacy",
    "—Å—É–≤–µ—Ä–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç", "–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞",
]

EXCLUDE_KEYWORDS = [
    "–∏–≥—Ä–∞", "–∏–≥—Ä—ã", "game", "games", "–≥–µ–π–º–ø–ª–µ–π", "gameplay",
    "dungeon", "quest", "–±–æ—Å—Å", "boss", "—Ä–µ–π–¥", "raid",
    "–æ–Ω–ª–∞–π–Ω-–∏–≥—Ä–∞", "–∏–≥—Ä–æ–≤–æ–π", "–≥–µ–π–º–∏–Ω–≥", "gaming",
    "playstation", "xbox", "nintendo", "steam",
    "—à—É—Ç–µ—Ä", "rpg", "mmorpg", "moba", "battle royale",
]

# ---------------- STATE ----------------

if os.path.exists(POSTED_FILE):
    with open(POSTED_FILE, "r", encoding="utf-8") as f:
        try:
            posted_data = json.load(f)
            if isinstance(posted_data, list) and posted_data and isinstance(posted_data[0], dict):
                posted_articles = {item["id"]: item.get("timestamp") for item in posted_data}
            else:
                posted_articles = {id_str: None for id_str in posted_data}
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ posted_articles: {e}")
            posted_articles = {}
else:
    posted_articles = {}

def save_posted_articles() -> None:
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π"""
    try:
        data = [{"id": id_str, "timestamp": ts} for id_str, ts in posted_articles.items()]
        with open(POSTED_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è posted_articles: {e}")

def clean_old_posts() -> None:
    """–£–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ä—à–µ RETENTION_DAYS –¥–Ω–µ–π"""
    global posted_articles
    now = datetime.now().timestamp()
    cutoff = now - (RETENTION_DAYS * 86400)

    old_count = len(posted_articles)
    posted_articles = {
        id_str: ts for id_str, ts in posted_articles.items()
        if ts is None or ts > cutoff
    }
    removed = old_count - len(posted_articles)
    if removed > 0:
        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –ø–æ—Å—Ç–æ–≤: {removed}")

    save_posted_articles()

def save_posted(article_id: str) -> None:
    """–û—Ç–º–µ—Ç–∏—Ç—å —Å—Ç–∞—Ç—å—é –∫–∞–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—É—é"""
    posted_articles[article_id] = datetime.now().timestamp()
    save_posted_articles()

# ---------------- HELPERS ----------------

def safe_get(url: str) -> Optional[str]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π HTTP GET –∑–∞–ø—Ä–æ—Å"""
    try:
        resp = requests.get(url, headers=HEADERS, timeout=15)
        if resp.status_code != 200:
            print(f"HTTP {resp.status_code} –¥–ª—è {url}")
            return None
        return resp.text
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ {url}: {e}")
        return None

def clean_text(text: str) -> str:
    """–û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤"""
    return " ".join(text.replace("\n", " ").replace("\r", " ").split())
# ---------------- PARSERS ----------------

def load_3dnews() -> List[Dict]:
    """–ü–∞—Ä—Å–∏–Ω–≥ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã 3DNews"""
    try:
        url = "https://3dnews.ru/"
        html = safe_get(url)
        if not html:
            return []

        articles = []
        parts = html.split('<a href="/')

        for part in parts[1:4]:
            try:
                href_end = part.find('"')
                title_start = part.find(">")
                title_end = part.find("</a>")
                if href_end == -1 or title_start == -1 or title_end == -1:
                    continue

                href = part[:href_end]
                title = clean_text(part[title_start + 1:title_end])
                if not title:
                    continue

                link = "https://3dnews.ru/" + href.lstrip("/")
                summary = ""

                desc_start = part.find('class="')
                if desc_start != -1:
                    desc_chunk = part[desc_start:desc_start + 500]
                    p_start = desc_chunk.find(">")
                    if p_start != -1:
                        p_end = desc_chunk.find("</", p_start)
                        if p_end != -1:
                            summary = clean_text(desc_chunk[p_start + 1:p_end])[:300]

                articles.append({
                    "id": link,
                    "title": title,
                    "summary": summary,
                    "link": link,
                    "source": "3DNews",
                    "published_parsed": datetime.now(),
                })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ 3DNews: {e}")
                continue

        print(f"DEBUG: 3DNews ‚Äì {len(articles)} —Å—Ç–∞—Ç–µ–π")
        return articles
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ 3DNews: {e}")
        return []

def load_rss(url: str, source: str) -> List[Dict]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ RSS –ª–µ–Ω—Ç—ã"""
    print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º RSS: {url}")
    articles = []

    try:
        feed = feedparser.parse(url)
        
        for entry in feed.entries[:30]:
            try:
                link = entry.get("link", "")
                title = clean_text(entry.get("title") or "")
                summary = clean_text(entry.get("summary") or entry.get("description") or "")[:400]
                if not link or not title:
                    continue

                published_parsed = datetime.now()
                if hasattr(entry, "published_parsed") and entry.published_parsed:
                    try:
                        published_parsed = datetime(*entry.published_parsed[:6])
                    except:
                        pass

                articles.append({
                    "id": link,
                    "title": title,
                    "summary": summary,
                    "link": link,
                    "source": source,
                    "published_parsed": published_parsed,
                })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ RSS {source}: {e}")
                continue

        print(f"DEBUG: {source} ‚Äì {len(articles)} —Å—Ç–∞—Ç–µ–π")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ RSS {url}: {e}")

    return articles

def load_articles_from_sites() -> List[Dict]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ç—å–∏ —Å–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    articles = []
    articles.extend(load_3dnews())
    articles.extend(load_rss("https://vc.ru/rss", "VC.ru/rss"))
    articles.extend(load_rss("https://habr.com/ru/rss/all/all/?fl=ru", "Habr/rss"))
    articles.extend(load_rss("https://xakep.ru/feed/", "Xakep.ru/rss"))
    print(f"–í–°–ï–ì–û –°–ü–ê–†–°–ï–ù–û: {len(articles)} —Å—Ç–∞—Ç–µ–π")
    return articles

# ---------------- FILTER ----------------

def filter_article(entry: Dict) -> Optional[str]:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—å—é –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
    title = entry.get("title", "")
    summary = entry.get("summary", "")
    text = (title + " " + summary).lower()

    if any(kw in text for kw in EXCLUDE_KEYWORDS):
        return None

    if any(kw in text for kw in STRONG_KEYWORDS):
        return "strong"
    if any(kw in text for kw in SOFT_KEYWORDS):
        return "soft"

    return None

# ---------------- PICK ARTICLE ----------------

PRIORITY_CHANNEL_KEYWORDS = [
    "vpn", "–≤–ø–Ω", "proxy", "–ø—Ä–æ–∫—Å–∏", "—Ä–æ—Å–∫–æ–º–Ω–∞–¥–∑–æ—Ä", "—Ä–∫–Ω",
    "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Å–∞–π—Ç–æ–≤", "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞", "–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ",
    "–æ–±—Ö–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫", "–æ–±—Ö–æ–¥ —Ü–µ–Ω–∑—É—Ä—ã", "—Ü–µ–Ω–∑—É—Ä–∞", "—Å—É–≤–µ—Ä–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç",
    "–±–µ–ª—ã–µ —Å–ø–∏—Å–∫–∏", "–º–∏–Ω—Ü–∏—Ñ—Ä—ã", "—Ä–æ—Å–∫–æ–º—Å–≤–æ–±–æ–¥–∞"
]

def pick_article(articles: List[Dict]) -> Optional[Dict]:
    """–í—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é —Å—Ç–∞—Ç—å—é –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
    strong_soft = []
    fallback = []
    third_stage = []
    skipped = 0

    for e in articles:
        aid = e.get("id")
        if aid in posted_articles:
            skipped += 1
            continue

        title = e.get("title", "")
        summary = e.get("summary", "")
        text = (title + " " + summary).lower()

        if any(kw in text for kw in EXCLUDE_KEYWORDS):
            continue

        level = filter_article(e)
        if level:
            score = 2 if level == "strong" else 1
            strong_soft.append((score, e))
        elif any(kw in text for kw in PRIORITY_CHANNEL_KEYWORDS):
            third_stage.append(e)
        else:
            fallback.append(e)

    print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö: {skipped}")
    print(f"–ü–æ –∫–ª—é—á–∞–º –Ω–∞–π–¥–µ–Ω–æ: {len(strong_soft)}, –∑–∞–ø–∞—Å–Ω—ã—Ö: {len(fallback)}, —Ç—Ä–µ—Ç–∏–π —ç—Ç–∞–ø: {len(third_stage)}")

    if strong_soft:
        strong_soft.sort(key=lambda x: (x[0], x[1].get("published_parsed", datetime.now())), reverse=True)
        return strong_soft[0][1]
    if fallback:
        fallback.sort(key=lambda x: x.get("published_parsed", datetime.now()), reverse=True)
        return fallback[0]
    if third_stage:
        third_stage.sort(key=lambda x: x.get("published_parsed", datetime.now()), reverse=True)
        return third_stage[0]

    return None

# ---------------- OPENAI ----------------

def short_summary(title: str, summary: str) -> str:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—Ä–∞—Ç–∫–∏–π –ø–æ—Å—Ç –¥–ª—è Telegram —á–µ—Ä–µ–∑ OpenAI"""
    news_text = f"{title}. {summary}" if summary else title
    prompt = (
        f"–ü–µ—Ä–µ–ø–∏—à–∏ –Ω–æ–≤–æ—Å—Ç—å –≤ —Å—Ç–∏–ª–µ Telegram-–∫–∞–Ω–∞–ª–∞:\n\n"
        f"{news_text}\n\n"
        f"–ü–†–ê–í–ò–õ–ê:\n"
        f"1. –ò—Å–ø–æ–ª—å–∑—É–π —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è.\n"
        f"2. –ï—Å–ª–∏ –µ—Å—Ç—å —Ü–∏—Ñ—Ä—ã ‚Äî –æ—Å—Ç–∞–≤–ª—è–π.\n"
        f"3. –û–±—ä–µ–º: 400‚Äì600 —Å–∏–º–≤–æ–ª–æ–≤.\n"
        f"4. –§–æ—Ä–º–∞—Ç:\n"
        f"   [—ç–º–æ–¥–∂–∏] –ß—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ\n"
        f"   [—ç–º–æ–¥–∂–∏] –ö–∞–∫–∞—è –±—ã–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞\n"
        f"   [—ç–º–æ–¥–∂–∏] –ß—Ç–æ —É–ª—É—á—à–∏–ª–æ—Å—å\n"
        f"   [—ç–º–æ–¥–∂–∏] –ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ\n\n"
        f"–í –∫–æ–Ω—Ü–µ –ù–ò–ß–ï–ì–û –Ω–µ –¥–æ–±–∞–≤–ª—è–π –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."
    )
    
    try:
        res = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
        )
        text = res.choices[0].message.content.strip()
        ps = "PSüí• –ö—Ç–æ –∑–∞ –∫–ª—é—á–∞–º–∏ üëâ https://t.me/+EdEfIkn83Wg3ZTE6"
        return text + "\n\n" + ps
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ OpenAI short_summary: {e}")
        ps = "PSüí• –ö—Ç–æ –∑–∞ –∫–ª—é—á–∞–º–∏ üëâ https://t.me/+EdEfIkn83Wg3ZTE6"
        return f"{title}\n\n{summary[:200]}\n\n{ps}"

def generate_image_prompt(title: str, summary: str) -> str:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ —á–µ—Ä–µ–∑ OpenAI"""
    base_prompt = f"Create cinematic, realistic image about: {title}. Dark tech atmosphere. No text. Max 200 chars."
    
    try:
        res = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": base_prompt}],
        )
        return res.choices[0].message.content.strip()[:200]
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ OpenAI generate_image_prompt: {e}")
        return f"Cinematic tech news illustration: {title[:100]}"

def generate_image_pollinations(prompt: str) -> Optional[str]:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Pollinations AI"""
    try:
        print("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É Pollinations...")
        url = f"https://image.pollinations.ai/prompt/{requests.utils.quote(prompt)}"
        params = {"width": "1024", "height": "1024", "nologo": "true", "model": "flux"}
        r = requests.get(url, params=params, timeout=60)
        if r.status_code != 200:
            print("–û—à–∏–±–∫–∞ Pollinations:", r.status_code)
            return None
        
        filename = f"news_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        with open(filename, "wb") as f:
            f.write(r.content)
        return filename
    except Exception as e:
        print("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏:", e)
        return None

# ---------------- AUTOPOST ----------------

async def autopost():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–≤—Ç–æ–ø–æ—Å—Ç–∏–Ω–≥–∞"""
    clean_old_posts()
    articles = load_articles_from_sites()
    if not articles:
        print("–ù–µ—Ç —Å—Ç–∞—Ç–µ–π")
        return

    art = pick_article(articles)
    if not art:
        print("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å—Ç–∞—Ç–µ–π")
        return

    aid = art["id"]
    if aid in posted_articles:
        print("–°—Ç–∞—Ç—å—è —É–∂–µ –≤ posted_articles, –≤—ã—Ö–æ–¥–∏–º")
        return

    print("\n–í—ã–±—Ä–∞–Ω–∞ —Å—Ç–∞—Ç—å—è:", art["title"], "\n")

    try:
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        text = short_summary(art["title"], art.get("summary", ""))
        img_prompt = generate_image_prompt(art["title"], art.get("summary", ""))
        img_file = generate_image_pollinations(img_prompt)

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram
        if img_file and os.path.exists(img_file):
            await bot.send_photo(
                chat_id=CHANNEL_ID,
                photo=FSInputFile(img_file),
                caption=text,
                parse_mode=ParseMode.HTML,
            )
            os.remove(img_file)
        else:
            await bot.send_message(
                chat_id=CHANNEL_ID,
                text=text,
                parse_mode=ParseMode.HTML,
            )

        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏
        save_posted(aid)
        print("‚úÖ –°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Telegram: {e}")
        print("–°—Ç–∞—Ç—å—è –ù–ï –±—É–¥–µ—Ç –ø–æ–º–µ—á–µ–Ω–∞ –∫–∞–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–∞—è –∏ –ø–æ–ø—ã—Ç–∞–µ—Ç—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å—Å—è —Å–Ω–æ–≤–∞.")

if __name__ == "__main__":
    asyncio.run(autopost())





















































