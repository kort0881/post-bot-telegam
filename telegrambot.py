import os
import json
import asyncio
import random
import re
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional

import requests
import feedparser
import urllib.parse
from aiogram import Bot
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.types import FSInputFile
from openai import OpenAI

# ============ CONFIG ============

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")

if not all([OPENAI_API_KEY, TELEGRAM_BOT_TOKEN, CHANNEL_ID]):
    raise ValueError("‚ùå –ù–µ –≤—Å–µ ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")

bot = Bot(
    token=TELEGRAM_BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML),
)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    )
}

POSTED_FILE = "posted_articles.json"
RETENTION_DAYS = 7
LAST_CATEGORY_FILE = "last_category.json"
LAST_SECURITY_FILE = "last_security_post.json"

MAX_ARTICLE_AGE_DAYS = 3

# ============ –ö–ê–¢–ï–ì–û–†–ò–ò –ò–°–¢–û–ß–ù–ò–ö–û–í ============

SOURCE_CATEGORIES = {
    "ai": ["Habr AI", "Habr ML", "Habr Neural", "Habr NLP", "Reuters AI", "Futurism AI"],
    "tech_ru": ["CNews", "ComNews", "3DNews", "iXBT", "Habr News"],
    "robotics": ["Habr Robotics"],
    "security": ["SecurityNews", "CyberAlerts"],
}

# –ü–æ—Ä—è–¥–æ–∫ —á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
CATEGORY_ROTATION = ["ai", "tech_ru", "ai", "robotics", "ai", "tech_ru", "security"]

# ============ –°–¢–ò–õ–ò –ü–û–°–¢–û–í ============

POST_STYLES = [
    {
        "name": "–≤–æ—Å—Ç–æ—Ä–∂–µ–Ω–Ω—ã–π_–≥–∏–∫",
        "intro": "–¢—ã –≤–µ–¥—ë—à—å –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –∫–∞–Ω–∞–ª –ø—Ä–æ –ò–ò –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏. –î–µ–ª–∏—à—å—Å—è –Ω–∞—Ö–æ–¥–∫–∞–º–∏ –∏ –Ω–æ–≤—ã–º–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞–º–∏, –±–µ–∑ —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ –ø–∞—Ñ–æ—Å–∞.",
        "tone": "–≠–Ω–µ—Ä–≥–∏—á–Ω—ã–π, –Ω–æ –æ–ø–∏—Ä–∞—é—â–∏–π—Å—è –Ω–∞ —Ñ–∞–∫—Ç—ã. –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∞–∫—Ü–µ–Ω—Ç –Ω–∞ —Å—É—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏.",
        "emojis": "üî•üöÄüí°ü§ñ‚ú®"
    },
    {
        "name": "–∞–Ω–∞–ª–∏—Ç–∏–∫",
        "intro": "–¢—ã ‚Äî —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –æ–±–æ–∑—Ä–µ–≤–∞—Ç–µ–ª—å. –û–±—ä—è—Å–Ω—è–µ—à—å –Ω–æ–≤—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –≤ –ò–ò –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, –≤—ã–¥–µ–ª—è–µ—à—å –≥–ª–∞–≤–Ω–æ–µ.",
        "tone": "–°–ø–æ–∫–æ–π–Ω—ã–π, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π. –§–∞–∫—Ç—ã + –∫–æ—Ä–æ—Ç–∫–∏–π –≤—ã–≤–æ–¥, —á–µ–º –ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–∞ —ç—Ç–∞ —Ä–∞–±–æ—Ç–∞ –∏–ª–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è.",
        "emojis": "üß†üìäüî¨üíª‚ö°"
    },
    {
        "name": "–∏—Ä–æ–Ω–∏—á–Ω—ã–π_–æ–±–æ–∑—Ä–µ–≤–∞—Ç–µ–ª—å",
        "intro": "–¢—ã ‚Äî –æ–±–æ–∑—Ä–µ–≤–∞—Ç–µ–ª—å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π. –ü–æ–∫–∞–∑—ã–≤–∞–µ—à—å, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Å–¥–µ–ª–∞–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏ –∏–ª–∏ –∏–Ω–∂–µ–Ω–µ—Ä—ã, –∏–Ω–æ–≥–¥–∞ —Å –ª—ë–≥–∫–æ–π –∏—Ä–æ–Ω–∏–µ–π.",
        "tone": "–ñ–∏–≤–æ–π, —Å –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–º —é–º–æ—Ä–æ–º, –Ω–æ –±–µ–∑ –ø—Ä–µ—É–≤–µ–ª–∏—á–µ–Ω–∏–π –∏ –±–µ–∑ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –ª–æ–∑—É–Ω–≥–æ–≤.",
        "emojis": "üëÄüéØüòèüõ†Ô∏èüí´"
    },
    {
        "name": "–ø—Ä–∞–∫—Ç–∏–∫",
        "intro": "–¢—ã ‚Äî –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–π —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –ò–ò. –ü–æ—è—Å–Ω—è–µ—à—å –ø–æ —Å—É—Ç–∏: –∫–∞–∫–∞—è –∑–∞–¥–∞—á–∞ —Ä–µ—à–∞–µ—Ç—Å—è, –∫–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω–æ —Ä–µ—à–µ–Ω–∏–µ –∏ –∫–æ–º—É —ç—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≥–æ–¥–∏—Ç—å—Å—è.",
        "tone": "–î–µ–ª–æ–≤–æ–π –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π. –ë–µ–∑ –ø–∞—Ñ–æ—Å–∞, –º–∏–Ω–∏–º—É–º –æ—Ü–µ–Ω–æ–∫.",
        "emojis": "‚öôÔ∏è‚úÖüì±üîßüí™"
    },
    {
        "name": "—Ñ—É—Ç—É—Ä–∏—Å—Ç",
        "intro": "–¢—ã ‚Äî —ç–Ω—Ç—É–∑–∏–∞—Å—Ç –±—É–¥—É—â–µ–≥–æ –ò–ò. –ü–æ–∫–∞–∑—ã–≤–∞–µ—à—å, –∫–∞–∫ –Ω–æ–≤–∞—è —Ä–∞–±–æ—Ç–∞, –º–æ–¥–µ–ª—å –∏–ª–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –≤ –∫–∞—Ä—Ç–∏–Ω—É —Ä–∞–∑–≤–∏—Ç–∏—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π.",
        "tone": "–°–¥–µ—Ä–∂–∞–Ω–Ω–æ –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–π. –û—Å–Ω–æ–≤–Ω–æ–π —É–ø–æ—Ä –Ω–∞ —Ñ–∞–∫—Ç—ã –∏ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –≤–∑–≥–ª—è–¥ –≤–ø–µ—Ä—ë–¥.",
        "emojis": "üåüüîÆüöÄüåç‚ú®"
    }
]

POST_STRUCTURES = [
    "hook_features_conclusion",
    "problem_solution",
    "straight_news"
]

# ============ –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê ============

AI_KEYWORDS = [
    "–Ω–µ–π—Ä–æ—Å–µ—Ç—å", "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏", "–Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å", "–∏–∏", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
    "neural network", "artificial intelligence",
    "llm", "gpt", "gpt-4", "gpt-5", "gpt-4o", "chatgpt", "claude", "gemini",
    "copilot", "mistral", "llama", "qwen", "gigachat", "yandexgpt",
    "kandinsky", "—à–µ–¥–µ–≤—Ä—É–º", "deepseek", "grok",
    "openai", "anthropic", "deepmind", "—Å–±–µ—Ä ai", "—è–Ω–¥–µ–∫—Å ai",
    "hugging face", "stability ai", "meta ai", "google ai",
    "stable diffusion", "midjourney", "dall-e", "sora", "runway",
    "–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π", "–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞",
    "–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ", "text-to-image", "text-to-video",
    "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "transformer",
    "—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä", "—è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å", "–º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π",
    "–¥–æ–æ–±—É—á–µ–Ω–∏–µ", "–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏", "–¥–∞—Ç–∞—Å–µ—Ç", "fine-tuning",
    "—á–∞—Ç-–±–æ—Ç", "–≥–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫", "–∞–≤—Ç–æ–ø–∏–ª–æ—Ç", "—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ",
    "–Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π", "ai-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç", "—É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫",
    "–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ", "–æ–±—Ä–∞–±–æ—Ç–∫–∞ —è–∑—ã–∫–∞", "nlp",
    "agi", "—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ", "–∞–≥–µ–Ω—Ç", "ai-–∞–≥–µ–Ω—Ç", "–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ",
    "—Ç–æ–∫–µ–Ω", "–±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å", "reasoning",
    "–æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "rlhf", "–ø—Ä–æ–º–ø—Ç", "prompt"
]

TECH_KEYWORDS = [
    "–ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª", "–∞–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–ª", "–≤—ã–ø—É—Å—Ç–∏–ª", "—Ä–µ–ª–∏–∑", "–∑–∞–ø—É—Å—Ç–∏–ª",
    "–Ω–æ–≤–∏–Ω–∫–∞", "–¥–µ–±—é—Ç", "–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è", "–ø–æ–∫–∞–∑–∞–ª", "unveiled",
    "—Å–º–∞—Ä—Ç—Ñ–æ–Ω", "–Ω–æ—É—Ç–±—É–∫", "–≥–∞–¥–∂–µ—Ç", "–¥–µ–≤–∞–π—Å", "—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ",
    "–Ω–æ—Å–∏–º–∞—è —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞", "—É–º–Ω—ã–µ —á–∞—Å—ã", "–Ω–∞—É—à–Ω–∏–∫–∏",
    "—Ä–æ–±–æ—Ç", "—Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞", "–¥—Ä–æ–Ω", "–±–µ—Å–ø–∏–ª–æ—Ç–Ω–∏–∫", "–∞–≤—Ç–æ–ø–∏–ª–æ—Ç",
    "–∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π", "boston dynamics", "tesla bot",
    "–∫–≤–∞–Ω—Ç–æ–≤—ã–π", "–∫–≤–∞–Ω—Ç–æ–≤—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä", "–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä", "—á–∏–ø",
    "gpu", "–≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞", "nvidia", "amd", "intel", "apple m",
    "spacex", "starship", "–∫–æ—Å–º–æ—Å", "—Ä–∞–∫–µ—Ç–∞", "—Å–ø—É—Ç–Ω–∏–∫",
    "starlink", "nasa", "—Ä–æ—Å–∫–æ—Å–º–æ—Å",
    "–≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å", "–¥–æ–ø–æ–ª–Ω–µ–Ω–Ω–∞—è —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å",
    "vr", "ar", "meta quest", "apple vision",
    "—ç–ª–µ–∫—Ç—Ä–æ–º–æ–±–∏–ª—å", "tesla", "—ç–ª–µ–∫—Ç—Ä–æ–∫–∞—Ä", "–±–∞—Ç–∞—Ä–µ—è",
    "–∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä", "–ø—Ä–æ—Ä—ã–≤", "–∏–Ω–Ω–æ–≤–∞—Ü–∏—è", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è",
    # –†–æ—Å—Å–∏–π—Å–∫–∏–π IT/—Ç–µ–ª–µ–∫–æ–º
    "–≥–æ—Å–∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è", "–º–∏–∫—Ä–æ—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞", "–ø–æ–ª—É–ø—Ä–æ–≤–æ–¥–Ω–∏–∫–∏",
    "–∏–º–ø–æ—Ä—Ç–æ–∑–∞–º–µ—â–µ–Ω–∏–µ", "–æ—Ç–µ—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä", "–±–∞–π–∫–∞–ª", "—ç–ª—å–±—Ä—É—Å",
    "—Å–æ—Ç–æ–≤—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä", "–º—Ç—Å", "–±–∏–ª–∞–π–Ω", "–º–µ–≥–∞—Ñ–æ–Ω", "—Ç–µ–ª–µ2", "—Ä–æ—Å—Ç–µ–ª–µ–∫–æ–º",
    "—Ç–∞—Ä–∏—Ñ", "–±–µ–∑–ª–∏–º–∏—Ç", "—Ä–æ—É–º–∏–Ω–≥", "5g", "lte",
    "—Ä–æ—Å–∫–æ–º–Ω–∞–¥–∑–æ—Ä", "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞", "vpn", "–∑–∞–º–µ–¥–ª–µ–Ω–∏–µ",
    "—è–Ω–¥–µ–∫—Å", "—Å–±–µ—Ä", "vk", "mail.ru", "ozon", "wildberries",
    "—Ü–æ–¥", "–¥–∞—Ç–∞-—Ü–µ–Ω—Ç—Ä", "–æ–±–ª–∞–∫–æ", "saas",
    "—Ç—Ä–∏–ª–ª–∏–æ–Ω", "–º–∏–ª–ª–∏–∞—Ä–¥ —Ä—É–±–ª–µ–π", "–≥–æ—Å—Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ",
]

SENSATIONAL_KEYWORDS = [
    "–≤–∑–ª–æ–º", "–≤–∑–ª–æ–º–∞–ª–∏", "—É—Ç–µ—á–∫–∞", "—É—Ç–µ–∫–ª–∏ –¥–∞–Ω–Ω—ã–µ", "data leak", "—É—Ç–µ—á–∫–æ–π –¥–∞–Ω–Ω—ã—Ö",
    "ransomware", "–≤—ã–∫—É–ø", "—à–∞–Ω—Ç–∞–∂", "–∑–∞—à–∏—Ñ—Ä–æ–≤–∞–ª", "—à–∏—Ñ—Ä–æ–≤–∞–ª—å—â–∏–∫",
    "–∞—Ç–∞–∫–∞", "–∫–∏–±–µ—Ä–∞—Ç–∞–∫–∞", "ddos", "—Ñ–∏—à–∏–Ω–≥", "—ç–∫—Å–ø–ª–æ–π—Ç", "—ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—è —É—è–∑–≤–∏–º–æ—Å—Ç–∏",
    "—É—è–∑–≤–∏–º–æ—Å—Ç—å", "0-day", "–Ω—É–ª–µ–≤–æ–≥–æ –¥–Ω—è", "—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ",
    "breach", "leak", "data breach", "hack", "was hacked",
    "vulnerability", "exploit", "bug bounty", "bugbounty",
    "security incident", "security flaw",
]

EXCLUDE_KEYWORDS = [
    "–∞–∫—Ü–∏–∏", "–∞–∫—Ü–∏—è", "–±–∏—Ä–∂–∞", "–∫–æ—Ç–∏—Ä–æ–≤–∫–∏", "–∏–Ω–¥–µ–∫—Å",
    "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "–∏–Ω–≤–µ—Å—Ç–æ—Ä", "–∏–Ω–≤–µ—Å—Ç–æ—Ä—ã", "–¥–∏–≤–∏–¥–µ–Ω–¥—ã",
    "ipo", "–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è", "—Ä—ã–Ω–æ—á–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å",
    "–≤—ã—Ä—É—á–∫–∞", "–ø—Ä–∏–±—ã–ª—å", "—É–±—ã—Ç–æ–∫", "–¥–æ—Ö–æ–¥", "–æ–±–æ—Ä–æ—Ç",
    "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á—ë—Ç", "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á–µ—Ç", "–∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç",
    "–º–∏–ª–ª–∏–∞—Ä–¥ –¥–æ–ª–ª–∞—Ä–æ–≤", "–º–∏–ª–ª–∏–æ–Ω –¥–æ–ª–ª–∞—Ä–æ–≤", "–º–ª—Ä–¥", "–º–ª–Ω —Ä—É–±–ª–µ–π",
    "–∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞", "–∫—É—Ä—Å –µ–≤—Ä–æ", "–∫—É—Ä—Å —Ä—É–±–ª—è", "–≤–∞–ª—é—Ç–∞",
    "—Ü–±", "—Ü–µ–Ω—Ç—Ä–æ–±–∞–Ω–∫", "—Å—Ç–∞–≤–∫–∞", "–∫–ª—é—á–µ–≤–∞—è —Å—Ç–∞–≤–∫–∞", "–∏–Ω—Ñ–ª—è—Ü–∏—è",
    "—ç–∫–æ–Ω–æ–º–∏–∫–∞", "—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π", "–≤–≤–ø", "—Ä–µ—Ü–µ—Å—Å–∏—è",
    "–±–∞–Ω–∫", "–∫—Ä–µ–¥–∏—Ç", "–∏–ø–æ—Ç–µ–∫–∞", "–≤–∫–ª–∞–¥", "–¥–µ–ø–æ–∑–∏—Ç",
    "—Ñ–æ–Ω–¥", "–≤–µ–Ω—á—É—Ä–Ω—ã–π", "—Ä–∞—É–Ω–¥ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è",
    "—Å–¥–µ–ª–∫–∞", "—Å–ª–∏—è–Ω–∏–µ", "–ø–æ–≥–ª–æ—â–µ–Ω–∏–µ", "m&a",
    "—Ä—ã–Ω–æ–∫", "–¥–æ–ª—è —Ä—ã–Ω–∫–∞", "–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã",
    "—Ü–µ–Ω–∞ –∞–∫—Ü–∏–π", "—Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ–º–ø–∞–Ω–∏–∏", "–æ—Ü–µ–Ω–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏",
    "–≤—ã—Ö–æ–¥ –Ω–∞ –±–∏—Ä–∂—É", "—Ä–∞–∑–º–µ—â–µ–Ω–∏–µ", "–ª–∏—Å—Ç–∏–Ω–≥",
    "–Ω–∞–∑–Ω–∞—á–µ–Ω", "–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ", "–æ—Ç—Å—Ç–∞–≤–∫–∞", "—É–≤–æ–ª–µ–Ω",
    "–≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä", "ceo", "–æ—Å–Ω–æ–≤–∞—Ç–µ–ª—å —É—à—ë–ª",
    "—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ —à—Ç–∞—Ç–∞", "—É–≤–æ–ª—å–Ω–µ–Ω–∏—è", "—Å–æ–∫—Ä–∞—â–µ–Ω–∏—è",
    "–æ—Ñ–∏—Å", "—à—Ç–∞–±-–∫–≤–∞—Ä—Ç–∏—Ä–∞", "–ø–µ—Ä–µ–µ–∑–¥ –∫–æ–º–ø–∞–Ω–∏–∏",
    "—Ç–µ–Ω–Ω–∏—Å", "—Ñ—É—Ç–±–æ–ª", "—Ö–æ–∫–∫–µ–π", "–±–∞—Å–∫–µ—Ç–±–æ–ª", "—Å–ø–æ—Ä—Ç", "–º–∞—Ç—á",
    "–æ–ª–∏–º–ø–∏–∞–¥–∞", "—á–µ–º–ø–∏–æ–Ω–∞—Ç", "—Ç—É—Ä–Ω–∏—Ä", "—Å–±–æ—Ä–Ω–∞—è",
    "–∏–≥—Ä–∞", "–≥–µ–π–º–ø–ª–µ–π", "playstation", "xbox", "steam", "nintendo",
    "–≤–∏–¥–µ–æ–∏–≥—Ä–∞", "–∫–æ–Ω—Å–æ–ª—å", "gaming",
    "–∫–∏–Ω–æ", "—Ñ–∏–ª—å–º", "—Å–µ—Ä–∏–∞–ª", "–º—É–∑—ã–∫–∞", "–∫–æ–Ω—Ü–µ—Ä—Ç", "–∞–∫—Ç—ë—Ä", "–∞–∫—Ç–µ—Ä",
    "–ø—Ä–µ–º—å–µ—Ä–∞", "—Ç—Ä–µ–π–ª–µ—Ä", "netflix", "–∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä",
    "–≤—ã–±–æ—Ä—ã", "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç", "–ø–∞—Ä–ª–∞–º–µ–Ω—Ç", "–ø–æ–ª–∏—Ç–∏–∫", "–¥–µ–ø—É—Ç–∞—Ç",
    "—Å–∞–Ω–∫—Ü–∏–∏", "–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ", "–º–∏–Ω–∏—Å—Ç—Ä", "–∑–∞–∫–æ–Ω", "–∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç",
    "–±–æ–ª–µ–∑–Ω—å", "covid", "–ø–∞–Ω–¥–µ–º–∏—è", "–≥—Ä–∏–ø–ø", "–≤–∞–∫—Ü–∏–Ω–∞",
    "–∫—Ä–∏–ø—Ç–æ", "bitcoin", "–±–∏—Ç–∫–æ–π–Ω", "–±–∏—Ç–∫–æ–∏–Ω", "ethereum",
    "nft", "–±–ª–æ–∫—á–µ–π–Ω", "–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞", "–º–∞–π–Ω–∏–Ω–≥",
    "—Å—É–¥", "—Å—É–¥–µ–±–Ω—ã–π", "–∞—Ä–µ—Å—Ç", "–ø—Ä–∏–≥–æ–≤–æ—Ä", "—Ç—é—Ä—å–º–∞", "—à—Ç—Ä–∞—Ñ",
    "–∏—Å–∫", "–∞–Ω—Ç–∏–º–æ–Ω–æ–ø–æ–ª—å–Ω—ã–π"
]

# ============ –ê–ù–¢–ò–†–ï–ö–õ–ê–ú–ù–´–ô –§–ò–õ–¨–¢–† ============

BAD_PHRASES = [
    "–ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ",
    "–ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ",
    "–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∑–∞—â–∏—Ç—É",
    "–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –Ω–∞–¥—ë–∂–Ω—É—é –∑–∞—â–∏—Ç—É",
    "–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∑–∞—â–∏—Ç—É",
    "–ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ —Å–≤–æ–∏—Ö –∑–∞–¥–∞—á–∞—Ö",
    "–ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–µ –¥—É–º–∞—Ç—å –æ–± —É–≥—Ä–æ–∑–∞—Ö",
    "–¥–µ–ª–∞–µ—Ç –±–∏–∑–Ω–µ—Å —É—Å—Ç–æ–π—á–∏–≤–µ–µ",
    "–ø–æ–∑–≤–æ–ª—è–µ—Ç –±–∏–∑–Ω–µ—Å—É —Ä–∞–±–æ—Ç–∞—Ç—å —É—Å—Ç–æ–π—á–∏–≤–µ–µ",
    "–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ø—Ä–æ—â–∞–µ—Ç",
    "–∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ —É–ø—Ä–æ—â–∞–µ—Ç",
    "–∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è",
    "–∏–¥–µ–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è",
    "–ø–æ–º–æ–≥–∞–µ—Ç –±–∏–∑–Ω–µ—Å—É —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ —Ä–∞–±–æ—Ç–∞—Ç—å",
]

def is_too_promotional(text: str) -> bool:
    low = text.lower()
    if any(p in low for p in BAD_PHRASES):
        return True
    if ("–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç" in low or "–ø–æ–∑–≤–æ–ª—è–µ—Ç" in low or "–ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ" in low) and \
       not any(k in low for k in ["–∑–∞ —Å—á—ë—Ç", "–∑–∞ —Å—á–µ—Ç", "–∏—Å–ø–æ–ª—å–∑—É—è", "—á–µ—Ä–µ–∑", "–Ω–∞–ø—Ä–∏–º–µ—Ä", "–≤ —Ç–æ–º —á–∏—Å–ª–µ", "—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏", "–∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞—Ñ–∏–∫–∞", "rate limiting", "–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫"]):
        return True
    return False

# ============ STATE ============

posted_articles: Dict[str, Optional[float]] = {}

if os.path.exists(POSTED_FILE):
    with open(POSTED_FILE, "r", encoding="utf-8") as f:
        try:
            posted_data = json.load(f)
            posted_articles = {item["id"]: item.get("timestamp") for item in posted_data}
        except Exception:
            posted_articles = {}

def save_posted_articles() -> None:
    data = [{"id": id_str, "timestamp": ts} for id_str, ts in posted_articles.items()]
    with open(POSTED_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def clean_old_posts() -> None:
    global posted_articles
    now = datetime.now().timestamp()
    cutoff = now - (RETENTION_DAYS * 86400)
    posted_articles = {
        id_str: ts for id_str, ts in posted_articles.items()
        if ts is None or ts > cutoff
    }
    save_posted_articles()

def save_posted(article_id: str) -> None:
    posted_articles[article_id] = datetime.now().timestamp()
    save_posted_articles()

# ============ CATEGORY ROTATION ============

def load_last_category() -> Dict:
    if not os.path.exists(LAST_CATEGORY_FILE):
        return {"category": None, "index": 0}
    try:
        with open(LAST_CATEGORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {"category": None, "index": 0}

def save_last_category(category: str, index: int) -> None:
    try:
        with open(LAST_CATEGORY_FILE, "w", encoding="utf-8") as f:
            json.dump({"category": category, "index": index}, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def get_next_category() -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ —Ä–æ—Ç–∞—Ü–∏–∏"""
    data = load_last_category()
    last_index = data.get("index", 0)
    next_index = (last_index + 1) % len(CATEGORY_ROTATION)
    return CATEGORY_ROTATION[next_index], next_index

def load_last_security_ts() -> Optional[float]:
    if not os.path.exists(LAST_SECURITY_FILE):
        return None
    try:
        with open(LAST_SECURITY_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data.get("ts")
    except Exception:
        return None

def save_last_security_ts() -> None:
    try:
        with open(LAST_SECURITY_FILE, "w", encoding="utf-8") as f:
            json.dump({"ts": datetime.now().timestamp()}, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

# ============ HELPERS ============

def clean_text(text: str) -> str:
    return " ".join(text.replace("\n", " ").replace("\r", " ").split())

def get_article_category(source: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å—Ç–∞—Ç—å–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É"""
    for category, sources in SOURCE_CATEGORIES.items():
        if source in sources:
            return category
    return "tech_ru"  # default

def detect_topic(title: str, summary: str) -> str:
    text = f"{title} {summary}".lower()

    if any(kw in text for kw in ["gpt", "chatgpt", "claude", "llm", "—è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å"]):
        return "llm"
    elif any(kw in text for kw in ["midjourney", "dall-e", "stable diffusion", "–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂"]):
        return "image_gen"
    elif any(kw in text for kw in ["—Ä–æ–±–æ—Ç", "robot", "–∞–≤—Ç–æ–Ω–æ–º–Ω"]):
        return "robotics"
    elif any(kw in text for kw in ["spacex", "–∫–æ—Å–º–æ—Å", "—Ä–∞–∫–µ—Ç–∞", "—Å–ø—É—Ç–Ω–∏–∫"]):
        return "space"
    elif any(kw in text for kw in ["nvidia", "gpu", "–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä", "—á–∏–ø"]):
        return "hardware"
    elif any(kw in text for kw in ["–Ω–µ–π—Ä–æ—Å–µ—Ç", "neural", "–∏–∏", "ai", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"]):
        return "ai"
    elif any(kw in text for kw in ["–æ–ø–µ—Ä–∞—Ç–æ—Ä", "—Ç–∞—Ä–∏—Ñ", "—Ç–µ–ª–µ–∫–æ–º", "—Ä–æ—Å—Ç–µ–ª–µ–∫–æ–º", "–º—Ç—Å", "–±–∏–ª–∞–π–Ω"]):
        return "telecom"
    elif any(kw in text for kw in ["–≥–æ—Å–∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è", "–∏–º–ø–æ—Ä—Ç–æ–∑–∞–º–µ—â–µ–Ω–∏–µ", "–º–∏–∫—Ä–æ—ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∞"]):
        return "ru_tech"
    else:
        return "tech"

def get_hashtags(topic: str) -> str:
    hashtag_map = {
        "llm": "#ChatGPT #LLM #–Ω–µ–π—Ä–æ—Å–µ—Ç–∏",
        "image_gen": "#AI #–≥–µ–Ω–µ—Ä–∞—Ü–∏—è #–Ω–µ–π—Ä–æ—Å–µ—Ç–∏",
        "robotics": "#—Ä–æ–±–æ—Ç—ã #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ #–±—É–¥—É—â–µ–µ",
        "space": "#–∫–æ—Å–º–æ—Å #SpaceX #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
        "hardware": "#–∂–µ–ª–µ–∑–æ #GPU #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
        "ai": "#AI #–Ω–µ–π—Ä–æ—Å–µ—Ç–∏ #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
        "tech": "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ #–Ω–æ–≤–∏–Ω–∫–∏ #–≥–∞–¥–∂–µ—Ç—ã",
        "telecom": "#—Ç–µ–ª–µ–∫–æ–º #—Å–≤—è–∑—å #–æ–ø–µ—Ä–∞—Ç–æ—Ä—ã",
        "ru_tech": "#–∏–º–ø–æ—Ä—Ç–æ–∑–∞–º–µ—â–µ–Ω–∏–µ #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ #–†–æ—Å—Å–∏—è",
        "sensational": "#–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å #—É—Ç–µ—á–∫–∞ #–≤–∑–ª–æ–º"
    }
    return hashtag_map.get(topic, "#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ #–Ω–æ–≤–æ—Å—Ç–∏")

def ensure_complete_sentence(text: str) -> str:
    text = text.strip()
    if not text:
        return text
    if text[-1] in '.!?':
        return text
    last_period = text.rfind('.')
    last_exclaim = text.rfind('!')
    last_question = text.rfind('?')
    last_end = max(last_period, last_exclaim, last_question)
    if last_end > 0:
        return text[:last_end + 1]
    return text + '.'

def trim_core_text_to_limit(core_text: str, max_core_length: int) -> str:
    core_text = core_text.strip()
    if len(core_text) <= max_core_length:
        return ensure_complete_sentence(core_text)
    sentence_pattern = r'(?<=[.!?])\s+'
    sentences = re.split(sentence_pattern, core_text)
    result = ""
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        candidate = (result + " " + sentence).strip() if result else sentence
        if len(candidate) <= max_core_length:
            result = candidate
        else:
            break
    if not result and sentences:
        result = sentences[0][:max_core_length]
        if len(result) == max_core_length and ' ' in result:
            result = result.rsplit(' ', 1)[0]
    return ensure_complete_sentence(result)

def build_final_post(core_text: str, hashtags: str, link: str, max_total: int = 1024) -> str:
    cta_line = "\n\n–§–æ—Ä–º–∞—Ç –º–∏–º–æ ‚Äî —Å—Ç–∞–≤—å üëé. –ó–∞—Ö–æ–¥–∏—Ç ‚Äî —Å—Ç–∞–≤—å üëç. –ü—Ä–∏—à—ë–ª —Ç–æ–ª—å–∫–æ –∑–∞ –º—è—Å–æ–º –∏ –∫–æ–Ω—Ñ–∏–≥–∞–º–∏ ‚Äî –∫–∏–¥–∞–π üî•."
    source_line = f'\n\nüîó <a href="{link}">–ò—Å—Ç–æ—á–Ω–∏–∫</a>'
    hashtag_line = f"\n\n{hashtags}"
    service_length = len(cta_line) + len(hashtag_line) + len(source_line)
    max_core_length = max_total - service_length - 10
    trimmed_core = trim_core_text_to_limit(core_text, max_core_length)
    final = trimmed_core + cta_line + hashtag_line + source_line
    if len(final) > max_total:
        overflow = len(final) - max_total
        trimmed_core = trim_core_text_to_limit(core_text, max_core_length - overflow - 20)
        final = trimmed_core + cta_line + hashtag_line + source_line
    return final

# ============ PARSERS ============

def load_rss(url: str, source: str) -> List[Dict]:
    articles = []
    try:
        feed = feedparser.parse(url)
        if feed.bozo and not feed.entries:
            print(f"‚ö†Ô∏è RSS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {source}")
            return articles
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RSS {source}: {e}")
        return articles

    now = datetime.now()
    max_age = timedelta(days=MAX_ARTICLE_AGE_DAYS)

    for entry in feed.entries[:50]:
        link = entry.get("link", "")
        if not link or link in posted_articles:
            continue

        pub_dt = now
        if hasattr(entry, "published_parsed") and entry.published_parsed:
            pub_dt = datetime(*entry.published_parsed[:6])
        elif hasattr(entry, "updated_parsed") and entry.updated_parsed:
            pub_dt = datetime(*entry.updated_parsed[:6])

        if now - pub_dt > max_age:
            continue

        articles.append({
            "id": link,
            "title": clean_text(entry.get("title") or ""),
            "summary": clean_text(
                entry.get("summary") or entry.get("description") or ""
            )[:700],
            "link": link,
            "source": source,
            "published_parsed": pub_dt,
            "category": get_article_category(source)
        })

    if articles:
        print(f"‚úÖ {source}: {len(articles)} —Å–≤–µ–∂–∏—Ö —Å—Ç–∞—Ç–µ–π")

    return articles

def load_articles_from_sites() -> List[Dict]:
    articles: List[Dict] = []

    # AI / ML / NLP —Å –•–∞–±—Ä–∞
    articles.extend(load_rss(
        "https://habr.com/ru/rss/hub/artificial_intelligence/all/?fl=ru",
        "Habr AI"
    ))
    articles.extend(load_rss(
        "https://habr.com/ru/rss/hub/machine_learning/all/?fl=ru",
        "Habr ML"
    ))
    articles.extend(load_rss(
        "https://habr.com/ru/rss/hub/neural_networks/all/?fl=ru",
        "Habr Neural"
    ))
    articles.extend(load_rss(
        "https://habr.com/ru/rss/hub/natural_language_processing/all/?fl=ru",
        "Habr NLP"
    ))
    articles.extend(load_rss(
        "https://habr.com/ru/rss/hub/robotics/all/?fl=ru",
        "Habr Robotics"
    ))

    # –•–∞–±—Ä –Ω–æ–≤–æ—Å—Ç–∏
    articles.extend(load_rss(
        "https://habr.com/ru/rss/news/?fl=ru",
        "Habr News"
    ))

    # –†–æ—Å—Å–∏–π—Å–∫–∏–µ IT/—Ç–µ–ª–µ–∫–æ–º
    articles.extend(load_rss("https://www.cnews.ru/inc/rss/news.xml", "CNews"))
    articles.extend(load_rss("https://3dnews.ru/news/rss/", "3DNews"))
    articles.extend(load_rss("https://www.ixbt.com/export/news.rss", "iXBT"))
    articles.extend(load_rss("https://www.comnews.ru/rss", "ComNews"))

    # –ö–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    articles.extend(load_rss("https://secnews.ru/rss/", "SecurityNews"))
    articles.extend(load_rss("https://cyberalerts.io/rss/latest-public", "CyberAlerts"))

    # –ó–∞—Ä—É–±–µ–∂–Ω—ã–µ AI
    articles.extend(load_rss(
        "https://www.reuters.com/technology/artificial-intelligence/rss",
        "Reuters AI"
    ))
    articles.extend(load_rss(
        "https://futurism.com/categories/ai-artificial-intelligence/feed",
        "Futurism AI"
    ))

    return articles

def filter_articles(articles: List[Dict]) -> Dict[str, List[Dict]]:
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç—å–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
    categorized = {
        "ai": [],
        "tech_ru": [],
        "robotics": [],
        "security": [],
        "sensational": []
    }

    for e in articles:
        text = f"{e['title']} {e['summary']}".lower()

        if any(kw in text for kw in EXCLUDE_KEYWORDS):
            continue

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–µ–Ω—Å–∞—Ü–∏–æ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        is_sensational = any(kw in text for kw in SENSATIONAL_KEYWORDS)
        
        if is_sensational:
            categorized["sensational"].append(e)
            continue

        category = e.get("category", "tech_ru")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        if any(kw in text for kw in AI_KEYWORDS):
            category = "ai"
        
        if category in categorized:
            categorized[category].append(e)
        else:
            categorized["tech_ru"].append(e)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ –¥–∞—Ç–µ
    for cat in categorized:
        categorized[cat].sort(key=lambda x: x["published_parsed"], reverse=True)
        print(f"üìÇ {cat}: {len(categorized[cat])} —Å—Ç–∞—Ç–µ–π")

    return categorized

# ============ –ì–ï–ù–ï–†–ê–¶–ò–Ø –¢–ï–ö–°–¢–ê ============

def build_dynamic_prompt(title: str, summary: str, style: dict, structure: str) -> str:
    news_text = f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}\n\n–¢–µ–∫—Å—Ç: {summary}"

    base_instructions = f"""
{style['intro']}

–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {style['tone']}
–≠–º–æ–¥–∑–∏: {style['emojis']}
"""

    structure_instructions = {
        "hook_features_conclusion": """
–°—Ç—Ä—É–∫—Ç—É—Ä–∞:
1. –ö–†–ê–¢–ö–û –°–£–¢–¨ ‚Äî —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å –∏ –≤ —á—ë–º –Ω–æ–≤–∏–∑–Ω–∞/–∂–µ—Å—Ç—å.
2. –ö–ê–ö –†–ê–ë–û–¢–ê–ï–¢ ‚Äî 2‚Äì3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–µ—Ö–∞–Ω–∏–∑–º–∞ –∏–ª–∏ –ø—Ä–∏—ë–º–∞ (–∫–∞–∫ —ç—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ/—Å–ª–æ–º–∞–ª–∏/–ø–æ—á–∏–Ω–∏–ª–∏).
3. –í–´–í–û–î ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º –ø–æ—Å–ª–µ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º: —á–µ–º —ç—Ç–æ –≥—Ä–æ–∑–∏—Ç –∏–ª–∏ –ø–æ–º–æ–≥–∞–µ—Ç –æ–±—ã—á–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º/—Ä–∞–∑—Ä–∞–±–∞–º.
""",
        "problem_solution": """
–°—Ç—Ä—É–∫—Ç—É—Ä–∞:
1. –ü–†–û–ë–õ–ï–ú–ê ‚Äî –∫–∞–∫—É—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥—ã—Ä—É, —Ä–∏—Å–∫ –∏–ª–∏ –±–æ–ª—å –∑–∞–∫—Ä—ã–≤–∞—é—Ç.
2. –†–ï–®–ï–ù–ò–ï ‚Äî –∫–∞–∫–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ä—ã, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏–ª–∏ —Ö–∞–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç.
3. –≠–§–§–ï–ö–¢ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º –ø–æ—Å–ª–µ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º: —á—Ç–æ —ç—Ç–æ –º–µ–Ω—è–µ—Ç –∏ –∑–∞ —á–µ–º —Ç–µ–ø–µ—Ä—å —Å—Ç–æ–∏—Ç —Å–ª–µ–¥–∏—Ç—å.
""",
        "straight_news": """
–°—Ç—Ä—É–∫—Ç—É—Ä–∞:
1. –§–ê–ö–¢ ‚Äî —á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ –±–µ–∑ —Ä–µ–∫–ª–∞–º—ã (–∑–∞–ø—É—Å–∫, —Ñ–µ–π–ª, –±–∞–≥, —É—Ç–µ—á–∫–∞, —Ä–µ–ª–∏–∑).
2. –¢–ï–•–î–ï–¢–ê–õ–ò ‚Äî 2‚Äì3 –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä–∏—ë–º–∞.
3. –ö–û–ù–¢–ï–ö–°–¢ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º –ø–æ—Å–ª–µ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º: –ø–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ –∏ –∫—Ç–æ –º–æ–∂–µ—Ç –ø–æ—Å—Ç—Ä–∞–¥–∞—Ç—å/–≤—ã–∏–≥—Ä–∞—Ç—å.
"""
    }

    prompt = f"""
{base_instructions}

–ù–û–í–û–°–¢–¨:
{news_text}

{structure_instructions.get(structure, structure_instructions['straight_news'])}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
‚Ä¢ –û–¥–∏–Ω —Å–≤—è–∑–Ω—ã–π –∞–±–∑–∞—Ü 500‚Äì800 —Å–∏–º–≤–æ–ª–æ–≤.
‚Ä¢ –Ø–∑—ã–∫: —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π.
‚Ä¢ –£–ø–æ–º—è–Ω–∏ 2‚Äì3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏—ë–º–∞ –∏–ª–∏ –º–µ—Ö–∞–Ω–∏–∑–º–∞.
‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ ‚Äî –≤—ã–≤–æ–¥ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å –∫ —á–∏—Ç–∞—Ç–µ–ª—é.
‚Ä¢ –¢–µ–∫—Å—Ç –û–ë–Ø–ó–ê–ù –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è . ! –∏–ª–∏ ?.
‚Ä¢ 0‚Äì2 —ç–º–æ–¥–∑–∏ –ø–æ –¥–µ–ª—É.
‚Ä¢ –ë–µ–∑ –≤—ã–¥—É–º–∫–∏ –∏ —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ —Ç–æ–Ω–∞.

–ó–ê–ü–†–ï–©–ï–ù–û:
‚Ä¢ –†–µ–∫–ª–∞–º–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏ –∫–ª–∏—à–µ —Ç–∏–ø–∞ ¬´–¥–µ–ª–∞–µ—Ç –±–∏–∑–Ω–µ—Å —É—Å—Ç–æ–π—á–∏–≤–µ–µ¬ª.
‚Ä¢ –ü—Ä–æ–¥–∞–∂–Ω—ã–π —Ç–æ–Ω, –ø—Ä–∏–∑—ã–≤—ã –∫—É–ø–∏—Ç—å/–ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å.
‚Ä¢ –û–±—Ä—ã–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —Å–µ—Ä–µ–¥–∏–Ω–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.

–í–´–î–ê–ô –¢–û–õ–¨–ö–û –¢–ï–ö–°–¢ –ü–û–°–¢–ê, –±–µ–∑ —Ö–µ—à—Ç–µ–≥–æ–≤ –∏ —Å—Å—ã–ª–æ–∫.
"""
    return prompt


def validate_generated_text(text: str) -> tuple[bool, str]:
    text = text.strip()
    if not text:
        return False, "–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç"
    if len(text) < 100:
        return False, f"–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)"
    if text[-1] not in '.!?':
        return False, "–¢–µ–∫—Å—Ç –Ω–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –∑–Ω–∞–∫–æ–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è"
    if text.count('(') != text.count(')'):
        return False, "–ù–µ–∑–∞–∫—Ä—ã—Ç—ã–µ —Å–∫–æ–±–∫–∏"
    if text.count('¬´') != text.count('¬ª'):
        return False, "–ù–µ–∑–∞–∫—Ä—ã—Ç—ã–µ –∫–∞–≤—ã—á–∫–∏"
    return True, "OK"


def short_summary(title: str, summary: str, link: str) -> Optional[str]:
    style = random.choice(POST_STYLES)
    structure = random.choice(POST_STRUCTURES)

    print(f"  üìù –°—Ç–∏–ª—å: {style['name']}, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {structure}")

    prompt = build_dynamic_prompt(title, summary, style, structure)

    max_attempts = 2
    
    for attempt in range(max_attempts):
        try:
            res = openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": (
                            "–¢—ã ‚Äî –∞–≤—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ Telegram-–∫–∞–Ω–∞–ª–∞ –ø—Ä–æ –ò–ò –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏. "
                            "–ü–∏—à–µ—à—å –ø–æ —Ñ–∞–∫—Ç–∞–º, —Å —É–ø–æ—Ä–æ–º –Ω–∞ –º–µ—Ö–∞–Ω–∏–∑–º—ã –∏ –ø–æ–¥—Ö–æ–¥—ã, –±–µ–∑ —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ —Ç–æ–Ω–∞. "
                            "–í–°–ï–ì–î–ê –∑–∞–∫–∞–Ω—á–∏–≤–∞–π —Ç–µ–∫—Å—Ç –ø–æ–ª–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º —Å —Ç–æ—á–∫–æ–π, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏–ª–∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–æ–º."
                        )
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=600,
            )
            core = res.choices[0].message.content.strip()

            if core.startswith('"') and core.endswith('"'):
                core = core[1:-1]
            if core.startswith('¬´') and core.endswith('¬ª'):
                core = core[1:-1]
            
            core = core.strip()

            is_valid, reason = validate_generated_text(core)
            if not is_valid:
                print(f"  ‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}: {reason}")
                if attempt < max_attempts - 1:
                    continue
                core = ensure_complete_sentence(core)

            if is_too_promotional(core):
                print("  ‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º —Ä–µ–∫–ª–∞–º–Ω—ã–π –ø–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                return None

            topic_raw = detect_topic(title, summary)
            if any(kw in (title + " " + summary).lower() for kw in SENSATIONAL_KEYWORDS):
                topic = "sensational"
            else:
                topic = topic_raw

            hashtags = get_hashtags(topic)
            final = build_final_post(core, hashtags, link, max_total=1024)

            print(f"  ‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –ø–æ—Å—Ç: {len(final)} —Å–∏–º–≤–æ–ª–æ–≤")
            return final

        except Exception as e:
            print(f"‚ùå OpenAI –æ—à–∏–±–∫–∞: {e}")
            if attempt < max_attempts - 1:
                time.sleep(2)
                continue
            return None
    
    return None

# ============ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–†–¢–ò–ù–û–ö ============

def generate_image(title: str, max_retries: int = 3) -> Optional[str]:
    image_styles = [
        "futuristic minimalist illustration, soft gradients, ",
        "abstract tech visualization, geometric shapes, ",
        "modern digital art, clean lines, ",
        "sci-fi concept art, atmospheric lighting, ",
        "sleek technology render, professional, "
    ]

    style = random.choice(image_styles)

    for attempt in range(max_retries):
        seed = random.randint(0, 10**7)
        clean_title = title[:60].replace('"', '').replace("'", "").replace('\n', ' ')

        prompt = (
            f"{style}{clean_title}, "
            "neural networks, innovation, technology, "
            "4k quality, no text, no letters, no words, "
            "clean composition, professional"
        )

        try:
            encoded = urllib.parse.quote(prompt)
            url = f"https://image.pollinations.ai/prompt/{encoded}?seed={seed}&width=1024&height=1024&nologo=true"

            print(f"  üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...")

            resp = requests.get(url, timeout=90, headers=HEADERS)

            if resp.status_code == 200:
                content_type = resp.headers.get('content-type', '')
                if 'image' in content_type and len(resp.content) > 10000:
                    fname = f"img_{seed}.jpg"
                    with open(fname, "wb") as f:
                        f.write(resp.content)
                    print(f"  ‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {fname}")
                    return fname
                else:
                    print(f"  ‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –Ω–µ–≤–µ—Ä–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (size: {len(resp.content)})")
            else:
                print(f"  ‚ö†Ô∏è HTTP {resp.status_code}")

        except requests.Timeout:
            print("  ‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        except requests.RequestException as e:
            print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")
        except Exception as e:
            print(f"  ‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")

        if attempt < max_retries - 1:
            await_time = (attempt + 1) * 2
            print(f"  ‚è≥ –ñ–¥—ë–º {await_time}—Å –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
            time.sleep(await_time)

    print("  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
    return None

def cleanup_image(filepath: Optional[str]) -> None:
    if filepath and os.path.exists(filepath):
        try:
            os.remove(filepath)
        except Exception as e:
            print(f"  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {filepath}: {e}")

# ============ –ê–í–¢–û–ü–û–°–¢ ============

async def autopost():
    clean_old_posts()
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π...")
    articles = load_articles_from_sites()
    categorized = filter_articles(articles)

    total = sum(len(v) for v in categorized.values())
    if total == 0:
        print("‚ùå –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π.")
        return

    print(f"üìä –í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {total}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ–Ω—Å–∞—Ü–∏–æ–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî –æ–Ω–∏ –∏–¥—É—Ç –≤–Ω–µ –æ—á–µ—Ä–µ–¥–∏
    last_security_ts = load_last_security_ts()
    now_ts = datetime.now().timestamp()
    security_cooldown = 7 * 86400  # –Ω–µ–¥–µ–ª—è

    posted_count = 0
    max_posts = 1

    # 1) –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ–Ω—Å–∞—Ü–∏–æ–Ω–Ω—ã–µ (–≤–Ω–µ —Ä–æ—Ç–∞—Ü–∏–∏)
    if categorized["sensational"]:
        art = categorized["sensational"][0]
        is_security_source = art.get("source") in ["SecurityNews", "CyberAlerts"]
        
        # Security –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî —Ç–æ–ª—å–∫–æ —Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é
        if is_security_source and last_security_ts and (now_ts - last_security_ts) < security_cooldown:
            print(f"‚è≥ Security –Ω–æ–≤–æ—Å—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–∞ (cooldown)")
        else:
            print(f"\nüö® –°–ï–ù–°–ê–¶–ò–Ø: {art['title'][:60]}... [{art['source']}]")
            
            post_text = short_summary(art["title"], art["summary"], art["link"])
            if post_text:
                img = generate_image(art["title"])
                try:
                    if img:
                        await bot.send_photo(CHANNEL_ID, photo=FSInputFile(img), caption=post_text)
                    else:
                        await bot.send_message(CHANNEL_ID, text=post_text)
                    
                    save_posted(art["id"])
                    posted_count += 1
                    
                    if is_security_source:
                        save_last_security_ts()
                    
                    print(f"‚úÖ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ —Å–µ–Ω—Å–∞—Ü–∏—è: {art['source']}")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
                finally:
                    cleanup_image(img)

    # 2) –ï—Å–ª–∏ —Å–µ–Ω—Å–∞—Ü–∏–π –Ω–µ—Ç –∏–ª–∏ –Ω–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª–∏ ‚Äî —Ä–∞–±–æ—Ç–∞–µ–º –ø–æ —Ä–æ—Ç–∞—Ü–∏–∏
    if posted_count == 0:
        next_category, next_index = get_next_category()
        print(f"\nüîÑ –†–æ—Ç–∞—Ü–∏—è: —Å–ª–µ–¥—É—é—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è ‚Äî {next_category}")

        # –ò—â–µ–º —Å—Ç–∞—Ç—å—é –≤ –Ω—É–∂–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        candidates = categorized.get(next_category, [])
        
        # –ï—Å–ª–∏ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—É—Å—Ç–æ ‚Äî –∏—â–µ–º –≤ –¥—Ä—É–≥–∏—Ö
        if not candidates:
            print(f"  ‚ö†Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏—è {next_category} –ø—É—Å—Ç–∞, –∏—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É...")
            for fallback_cat in ["ai", "tech_ru", "robotics"]:
                if categorized.get(fallback_cat):
                    candidates = categorized[fallback_cat]
                    next_category = fallback_cat
                    print(f"  ‚Ü™Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º {fallback_cat}")
                    break

        if candidates:
            art = candidates[0]
            print(f"\nüîç –û–±—Ä–∞–±–æ—Ç–∫–∞: {art['title'][:60]}... [{art['source']}]")

            post_text = short_summary(art["title"], art["summary"], art["link"])
            if post_text:
                img = generate_image(art["title"])
                try:
                    if img:
                        await bot.send_photo(CHANNEL_ID, photo=FSInputFile(img), caption=post_text)
                    else:
                        await bot.send_message(CHANNEL_ID, text=post_text)

                    save_posted(art["id"])
                    save_last_category(next_category, next_index)
                    posted_count += 1
                    print(f"‚úÖ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ [{next_category}]: {art['source']}")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
                finally:
                    cleanup_image(img)

    if posted_count == 0:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø–æ—Å—Ç–∞")
    else:
        print(f"\nüéâ –£—Å–ø–µ—à–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ –ø–æ—Å—Ç–æ–≤: {posted_count}")

async def main():
    try:
        await autopost()
    finally:
        await bot.session.close()

if __name__ == "__main__":
    asyncio.run(main())












































































































































































































































