import os
import json
import asyncio
import random
import re
import time
from datetime import datetime
from typing import List, Dict, Optional

import requests
import feedparser
import urllib.parse
from aiogram import Bot
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.types import FSInputFile
from openai import OpenAI

# ============ CONFIG ============

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")

if not all([OPENAI_API_KEY, TELEGRAM_BOT_TOKEN, CHANNEL_ID]):
    print("‚ö†Ô∏è WARNING: –ù–µ –≤—Å–µ –∫–ª—é—á–∏ –Ω–∞–π–¥–µ–Ω—ã –≤ ENV!")

bot = Bot(
    token=TELEGRAM_BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML),
)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    )
}

POSTED_FILE = "posted_articles.json"
RETENTION_DAYS = 7
TELEGRAM_CAPTION_LIMIT = 1024

# ============ –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê (–¢–û–õ–¨–ö–û AI) ============

AI_KEYWORDS = [
    "–Ω–µ–π—Ä–æ—Å–µ—Ç—å", "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏", "–Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å", "–∏–∏", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
    "neural network", "artificial intelligence",
    "llm", "gpt", "gpt-4", "gpt-5", "gpt-4o", "chatgpt", "claude", "gemini",
    "copilot", "mistral", "llama", "qwen", "gigachat", "yandexgpt",
    "kandinsky", "—à–µ–¥–µ–≤—Ä—É–º", "deepseek", "grok",
    "openai", "anthropic", "deepmind", "—Å–±–µ—Ä ai", "—è–Ω–¥–µ–∫—Å ai",
    "hugging face", "stability ai", "meta ai", "google ai",
    "stable diffusion", "midjourney", "dall-e", "sora", "runway",
    "–≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π", "–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", "–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞",
    "–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ", "text-to-image", "text-to-video",
    "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "transformer",
    "—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä", "—è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å", "–º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π",
    "–¥–æ–æ–±—É—á–µ–Ω–∏–µ", "–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏", "–¥–∞—Ç–∞—Å–µ—Ç", "fine-tuning",
    "—á–∞—Ç-–±–æ—Ç", "–≥–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫", "–∞–≤—Ç–æ–ø–∏–ª–æ—Ç", "—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ",
    "–Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π", "ai-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç", "—É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫",
    "–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ", "–æ–±—Ä–∞–±–æ—Ç–∫–∞ —è–∑—ã–∫–∞", "nlp",
    "agi", "—Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ", "–∞–≥–µ–Ω—Ç", "ai-–∞–≥–µ–Ω—Ç", "–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ",
    "—Ç–æ–∫–µ–Ω", "–±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å", "reasoning",
    "–æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º", "rlhf", "–ø—Ä–æ–º–ø—Ç", "prompt"
]

# –°–¢–û–ü-–°–õ–û–í–ê (–ß—Ç–æ–±—ã –Ω–µ –ø–æ—Å—Ç–∏–ª –ø—Ä–æ —Ñ–∏–Ω–∞–Ω—Å—ã –∏ –ø–æ–ª–∏—Ç–∏–∫—É)
EXCLUDE_KEYWORDS = [
    "–∞–∫—Ü–∏–∏", "–∞–∫—Ü–∏—è", "–±–∏—Ä–∂–∞", "–∫–æ—Ç–∏—Ä–æ–≤–∫–∏", "–∏–Ω–¥–µ–∫—Å",
    "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "–∏–Ω–≤–µ—Å—Ç–æ—Ä", "–∏–Ω–≤–µ—Å—Ç–æ—Ä—ã", "–¥–∏–≤–∏–¥–µ–Ω–¥—ã",
    "ipo", "–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è", "—Ä—ã–Ω–æ—á–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å",
    "–≤—ã—Ä—É—á–∫–∞", "–ø—Ä–∏–±—ã–ª—å", "—É–±—ã—Ç–æ–∫", "–¥–æ—Ö–æ–¥", "–æ–±–æ—Ä–æ—Ç",
    "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á—ë—Ç", "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á–µ—Ç", "–∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç",
    "–º–∏–ª–ª–∏–∞—Ä–¥ –¥–æ–ª–ª–∞—Ä–æ–≤", "–º–∏–ª–ª–∏–æ–Ω –¥–æ–ª–ª–∞—Ä–æ–≤", "–º–ª—Ä–¥", "–º–ª–Ω —Ä—É–±–ª–µ–π",
    "–∫—É—Ä—Å –¥–æ–ª–ª–∞—Ä–∞", "–∫—É—Ä—Å –µ–≤—Ä–æ", "–∫—É—Ä—Å —Ä—É–±–ª—è", "–≤–∞–ª—é—Ç–∞",
    "—Ü–±", "—Ü–µ–Ω—Ç—Ä–æ–±–∞–Ω–∫", "—Å—Ç–∞–≤–∫–∞", "–∫–ª—é—á–µ–≤–∞—è —Å—Ç–∞–≤–∫–∞", "–∏–Ω—Ñ–ª—è—Ü–∏—è",
    "—ç–∫–æ–Ω–æ–º–∏–∫–∞", "—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π", "–≤–≤–ø", "—Ä–µ—Ü–µ—Å—Å–∏—è",
    "–±–∞–Ω–∫", "–∫—Ä–µ–¥–∏—Ç", "–∏–ø–æ—Ç–µ–∫–∞", "–≤–∫–ª–∞–¥", "–¥–µ–ø–æ–∑–∏—Ç",
    "—Ñ–æ–Ω–¥", "–≤–µ–Ω—á—É—Ä–Ω—ã–π", "—Ä–∞—É–Ω–¥ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è",
    "—Å–¥–µ–ª–∫–∞", "—Å–ª–∏—è–Ω–∏–µ", "–ø–æ–≥–ª–æ—â–µ–Ω–∏–µ", "m&a",
    "—Ä—ã–Ω–æ–∫", "–¥–æ–ª—è —Ä—ã–Ω–∫–∞", "–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã",
    "—Ü–µ–Ω–∞ –∞–∫—Ü–∏–π", "—Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ–º–ø–∞–Ω–∏–∏", "–æ—Ü–µ–Ω–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏",
    "–≤—ã—Ö–æ–¥ –Ω–∞ –±–∏—Ä–∂—É", "—Ä–∞–∑–º–µ—â–µ–Ω–∏–µ", "–ª–∏—Å—Ç–∏–Ω–≥",
    "–Ω–∞–∑–Ω–∞—á–µ–Ω", "–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ", "–æ—Ç—Å—Ç–∞–≤–∫–∞", "—É–≤–æ–ª–µ–Ω",
    "–≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä", "ceo", "–æ—Å–Ω–æ–≤–∞—Ç–µ–ª—å —É—à—ë–ª",
    "—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ —à—Ç–∞—Ç–∞", "—É–≤–æ–ª—å–Ω–µ–Ω–∏—è", "—Å–æ–∫—Ä–∞—â–µ–Ω–∏—è",
    "–æ—Ñ–∏—Å", "—à—Ç–∞–±-–∫–≤–∞—Ä—Ç–∏—Ä–∞", "–ø–µ—Ä–µ–µ–∑–¥ –∫–æ–º–ø–∞–Ω–∏–∏",
    "—Ç–µ–Ω–Ω–∏—Å", "—Ñ—É—Ç–±–æ–ª", "—Ö–æ–∫–∫–µ–π", "–±–∞—Å–∫–µ—Ç–±–æ–ª", "—Å–ø–æ—Ä—Ç", "–º–∞—Ç—á",
    "–æ–ª–∏–º–ø–∏–∞–¥–∞", "—á–µ–º–ø–∏–æ–Ω–∞—Ç", "—Ç—É—Ä–Ω–∏—Ä", "—Å–±–æ—Ä–Ω–∞—è",
    "–∏–≥—Ä–∞", "–≥–µ–π–º–ø–ª–µ–π", "playstation", "xbox", "steam", "nintendo",
    "–≤–∏–¥–µ–æ–∏–≥—Ä–∞", "–∫–æ–Ω—Å–æ–ª—å", "gaming",
    "–∫–∏–Ω–æ", "—Ñ–∏–ª—å–º", "—Å–µ—Ä–∏–∞–ª", "–º—É–∑—ã–∫–∞", "–∫–æ–Ω—Ü–µ—Ä—Ç", "–∞–∫—Ç—ë—Ä", "–∞–∫—Ç–µ—Ä",
    "–ø—Ä–µ–º—å–µ—Ä–∞", "—Ç—Ä–µ–π–ª–µ—Ä", "netflix", "–∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä",
    "–≤—ã–±–æ—Ä—ã", "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç", "–ø–∞—Ä–ª–∞–º–µ–Ω—Ç", "–ø–æ–ª–∏—Ç–∏–∫", "–¥–µ–ø—É—Ç–∞—Ç",
    "—Å–∞–Ω–∫—Ü–∏–∏", "–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ", "–º–∏–Ω–∏—Å—Ç—Ä", "–∑–∞–∫–æ–Ω", "–∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç",
    "–±–æ–ª–µ–∑–Ω—å", "covid", "–ø–∞–Ω–¥–µ–º–∏—è", "–≥—Ä–∏–ø–ø", "–≤–∞–∫—Ü–∏–Ω–∞",
    "–∫—Ä–∏–ø—Ç–æ", "bitcoin", "–±–∏—Ç–∫–æ–π–Ω", "–±–∏—Ç–∫–æ–∏–Ω", "ethereum",
    "nft", "–±–ª–æ–∫—á–µ–π–Ω", "–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞", "–º–∞–π–Ω–∏–Ω–≥",
    "—Å—É–¥", "—Å—É–¥–µ–±–Ω—ã–π", "–∞—Ä–µ—Å—Ç", "–ø—Ä–∏–≥–æ–≤–æ—Ä", "—Ç—é—Ä—å–º–∞", "—à—Ç—Ä–∞—Ñ",
    "–∏—Å–∫", "–∞–Ω—Ç–∏–º–æ–Ω–æ–ø–æ–ª—å–Ω—ã–π"
]

# ============ –ê–ù–¢–ò–†–ï–ö–õ–ê–ú–ù–´–ô –§–ò–õ–¨–¢–† ============

BAD_PHRASES = [
    "–ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ",
    "–ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ",
    "–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∑–∞—â–∏—Ç—É",
    "–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –Ω–∞–¥—ë–∂–Ω—É—é –∑–∞—â–∏—Ç—É",
    "–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∑–∞—â–∏—Ç—É",
    "–ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ —Å–≤–æ–∏—Ö –∑–∞–¥–∞—á–∞—Ö",
    "–ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–µ –¥—É–º–∞—Ç—å –æ–± —É–≥—Ä–æ–∑–∞—Ö",
    "–¥–µ–ª–∞–µ—Ç –±–∏–∑–Ω–µ—Å —É—Å—Ç–æ–π—á–∏–≤–µ–µ",
    "–ø–æ–∑–≤–æ–ª—è–µ—Ç –±–∏–∑–Ω–µ—Å—É —Ä–∞–±–æ—Ç–∞—Ç—å —É—Å—Ç–æ–π—á–∏–≤–µ–µ",
    "–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ø—Ä–æ—â–∞–µ—Ç",
    "–∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ —É–ø—Ä–æ—â–∞–µ—Ç",
    "–∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è",
    "–∏–¥–µ–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è",
    "–ø–æ–º–æ–≥–∞–µ—Ç –±–∏–∑–Ω–µ—Å—É —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ —Ä–∞–±–æ—Ç–∞—Ç—å",
]

def is_too_promotional(text: str) -> bool:
    low = text.lower()
    if any(p in low for p in BAD_PHRASES):
        return True
    # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ "–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç" –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏
    if ("–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç" in low or "–ø–æ–∑–≤–æ–ª—è–µ—Ç" in low or "–ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ" in low) and \
       not any(k in low for k in ["–∑–∞ —Å—á—ë—Ç", "–∑–∞ —Å—á–µ—Ç", "–∏—Å–ø–æ–ª—å–∑—É—è", "—á–µ—Ä–µ–∑", "–Ω–∞–ø—Ä–∏–º–µ—Ä", "–≤ —Ç–æ–º —á–∏—Å–ª–µ", "—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏", "–∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞—Ñ–∏–∫–∞", "rate limiting", "–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤—â–∏–∫"]):
        return True
    return False

# ============ STATE ============

posted_articles: Dict[str, Optional[float]] = {}

if os.path.exists(POSTED_FILE):
    with open(POSTED_FILE, "r", encoding="utf-8") as f:
        try:
            posted_data = json.load(f)
            posted_articles = {item["id"]: item.get("timestamp") for item in posted_data}
        except Exception:
            posted_articles = {}

def save_posted_articles() -> None:
    data = [{"id": id_str, "timestamp": ts} for id_str, ts in posted_articles.items()]
    with open(POSTED_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def clean_old_posts() -> None:
    global posted_articles
    now = datetime.now().timestamp()
    cutoff = now - (RETENTION_DAYS * 86400)
    posted_articles = {
        id_str: ts for id_str, ts in posted_articles.items()
        if ts is None or ts > cutoff
    }
    save_posted_articles()

def save_posted(article_id: str) -> None:
    posted_articles[article_id] = datetime.now().timestamp()
    save_posted_articles()

# ============ HELPERS ============

def clean_text(text: str) -> str:
    return " ".join(text.replace("\n", " ").replace("\r", " ").split())

def detect_topic(title: str, summary: str) -> str:
    text = f"{title} {summary}".lower()

    if any(kw in text for kw in ["gpt", "chatgpt", "claude", "llm", "—è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å"]):
        return "llm"
    elif any(kw in text for kw in ["midjourney", "dall-e", "stable diffusion", "–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂"]):
        return "image_gen"
    elif any(kw in text for kw in ["—Ä–æ–±–æ—Ç", "robot", "–∞–≤—Ç–æ–Ω–æ–º–Ω"]):
        return "robotics"
    elif any(kw in text for kw in ["spacex", "–∫–æ—Å–º–æ—Å", "—Ä–∞–∫–µ—Ç–∞", "—Å–ø—É—Ç–Ω–∏–∫"]):
        return "space"
    elif any(kw in text for kw in ["nvidia", "gpu", "–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä", "—á–∏–ø"]):
        return "hardware"
    elif any(kw in text for kw in ["–Ω–µ–π—Ä–æ—Å–µ—Ç", "neural", "–∏–∏", "ai", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"]):
        return "ai"
    else:
        return "ai"

def get_hashtags(topic: str) -> str:
    hashtag_map = {
        "llm": "#ChatGPT #LLM #–Ω–µ–π—Ä–æ—Å–µ—Ç–∏",
        "image_gen": "#AI #–≥–µ–Ω–µ—Ä–∞—Ü–∏—è #–Ω–µ–π—Ä–æ—Å–µ—Ç–∏",
        "robotics": "#—Ä–æ–±–æ—Ç—ã #AI #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
        "space": "#–∫–æ—Å–º–æ—Å #SpaceX #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
        "hardware": "#–∂–µ–ª–µ–∑–æ #GPU #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
        "ai": "#AI #–Ω–µ–π—Ä–æ—Å–µ—Ç–∏ #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
    }
    return hashtag_map.get(topic, "#AI #–Ω–µ–π—Ä–æ—Å–µ—Ç–∏ #—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏")

def ensure_complete_sentence(text: str) -> str:
    text = text.strip()
    if not text: return text
    if text[-1] in '.!?': return text
    last_period = text.rfind('.')
    last_exclaim = text.rfind('!')
    last_question = text.rfind('?')
    last_end = max(last_period, last_exclaim, last_question)
    if last_end > 0: return text[:last_end + 1]
    return text + '.'

def trim_core_text_to_limit(core_text: str, max_core_length: int) -> str:
    core_text = core_text.strip()
    if len(core_text) <= max_core_length:
        return ensure_complete_sentence(core_text)
    sentence_pattern = r'(?<=[.!?])\s+'
    sentences = re.split(sentence_pattern, core_text)
    result = ""
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence: continue
        candidate = (result + " " + sentence).strip() if result else sentence
        if len(candidate) <= max_core_length:
            result = candidate
        else:
            break
    if not result and sentences:
        result = sentences[0][:max_core_length]
        if len(result) == max_core_length and ' ' in result:
            result = result.rsplit(' ', 1)[0]
    return ensure_complete_sentence(result)

def build_final_post(core_text: str, hashtags: str, link: str, max_total: int = 1024) -> str:
    cta_line = "\n\nüî• ‚Äî –æ–≥–æ–Ω—å! | üóø ‚Äî –Ω—É —Ç–∞–∫–æ–µ | ‚ö° ‚Äî –±—É–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è"
    source_line = f'\nüîó <a href="{link}">–ò—Å—Ç–æ—á–Ω–∏–∫</a>'
    hashtag_line = f"\n\n{hashtags}"
    
    service_length = len(cta_line) + len(hashtag_line) + len(source_line)
    max_core_length = max_total - service_length - 10
    
    trimmed_core = trim_core_text_to_limit(core_text, max_core_length)
    
    final = trimmed_core + cta_line + hashtag_line + source_line
    return final

# ============ PARSERS ============

def load_rss(url: str, source: str) -> List[Dict]:
    articles = []
    try:
        feed = feedparser.parse(url)
        if feed.bozo and not feed.entries:
            print(f"‚ö†Ô∏è RSS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {source}")
            return articles
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RSS {source}: {e}")
        return articles

    for entry in feed.entries[:30]:
        link = entry.get("link", "")
        if not link or link in posted_articles:
            continue
        articles.append({
            "id": link,
            "title": clean_text(entry.get("title") or ""),
            "summary": clean_text(
                entry.get("summary") or entry.get("description") or ""
            )[:700],
            "link": link,
            "source": source,
            "published_parsed": datetime.now()
        })
    return articles

def load_articles_from_sites() -> List[Dict]:
    articles: List[Dict] = []
    # HABR
    articles.extend(load_rss("https://habr.com/ru/rss/hub/artificial_intelligence/all/?fl=ru", "Habr AI"))
    articles.extend(load_rss("https://habr.com/ru/rss/hub/machine_learning/all/?fl=ru", "Habr ML"))
    articles.extend(load_rss("https://habr.com/ru/rss/hub/neural_networks/all/?fl=ru", "Habr Neural"))
    
    # TECH (–ë—É–¥–µ—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –Ω–∏–∂–µ, –µ—Å–ª–∏ –Ω–µ—Ç —Å–ª–æ–≤ –ø—Ä–æ AI)
    articles.extend(load_rss("https://3dnews.ru/news/rss/", "3DNews"))
    articles.extend(load_rss("https://www.ixbt.com/export/news.rss", "iXBT"))
    articles.extend(load_rss("https://nplus1.ru/rss", "N+1"))
    articles.extend(load_rss("https://hightech.fm/feed", "–•–∞–π—Ç–µ–∫"))
    
    return articles

def filter_articles(articles: List[Dict]) -> List[Dict]:
    valid_articles = []

    for e in articles:
        text = f"{e['title']} {e['summary']}".lower()

        # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –°–¢–û–ü-–°–õ–û–í–ê
        if any(kw in text for kw in EXCLUDE_KEYWORDS):
            continue

        # 2. –¢–µ–ø–µ—Ä—å –°–¢–†–û–ì–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å—Ç—å –ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ AI?
        # –ï—Å–ª–∏ –Ω–µ—Ç - –Ω–æ–≤–æ—Å—Ç—å –Ω–µ –±–µ—Ä–µ–º, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∞ —Å —Ö–∞–π—Ç–µ–∫ —Å–∞–π—Ç–∞.
        if any(kw in text for kw in AI_KEYWORDS):
            valid_articles.append(e)

    valid_articles.sort(key=lambda x: x["published_parsed"], reverse=True)
    return valid_articles

# ============ –ì–ï–ù–ï–†–ê–¶–ò–Ø –¢–ï–ö–°–¢–ê ============

def build_dynamic_prompt(title: str, summary: str) -> str:
    news_text = f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}\n\n–¢–µ–∫—Å—Ç: {summary}"

    prompt = f"""
–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∞–≤—Ç–æ—Ä –∫–∞–Ω–∞–ª–∞ "–î–æ—Å—Ç—É–ø –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É" (–ø—Ä–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∏ –ò–ò).
–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –ù–∞–ø–∏—Å–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –∏ —É–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π –ø–æ—Å—Ç.

–ù–û–í–û–°–¢–¨:
{news_text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –¢–ï–ö–°–¢–£:
1. –ù–ê–ß–ê–õ–û: –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–∞—á–Ω–∏ —Å —Ñ—Ä–∞–∑—ã "–í—Å–µ–º –ø—Ä–∏–≤–µ—Ç! üëã" –∏–ª–∏ "–ü—Ä–∏–≤–µ—Ç, –¥—Ä—É–∑—å—è! ‚úåÔ∏è".
2. –°–¢–ò–õ–¨: 
   - –ü–∏—à–∏ –∂–∏–≤—ã–º —è–∑—ã–∫–æ–º, –∫–∞–∫ –±—É–¥—Ç–æ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—à—å –¥—Ä—É–≥—É.
   - –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å—É—Ö–æ–π "–Ω–æ–≤–æ—Å—Ç–Ω–æ–π" —Å—Ç–∏–ª—å. 
   - –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ä–µ–∫–ª–∞–º–Ω—ã–π —Å—Ç–∏–ª—å ("—É–Ω–∏–∫–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ", "—Å–ø–µ—à–∏—Ç–µ –≤–∏–¥–µ—Ç—å").
   - –ò–∑–±–µ–≥–∞–π —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–∏—á–∞—Å—Ç–∏–π, –ø–∏—à–∏ –ø—Ä–æ—Å—Ç–æ.
3. –°–û–î–ï–†–ñ–ê–ù–ò–ï:
   - –û–±—ä—è—Å–Ω–∏ —Å—É—Ç—å: —á—Ç–æ –∏–º–µ–Ω–Ω–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ?
   - –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç? (–¥–æ–±–∞–≤—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å, –Ω–æ –æ–±—ä—è—Å–Ω–∏ –∏—Ö –ø—Ä–æ—Å—Ç–æ).
   - –ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ? (–ø–æ–ª—å–∑–∞ –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –∏–ª–∏ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏).
4. –û–ë–™–ï–ú: –ù–∞–ø–∏—à–∏ –ø—Ä–∏–º–µ—Ä–Ω–æ 1000-1200 –∑–Ω–∞–∫–æ–≤. –ü–æ—Å—Ç –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–º –æ–≥—Ä—ã–∑–∫–æ–º.

–ó–ê–ü–†–ï–¢–´:
- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–≤–∞: "—Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π", "–±–µ—Å–ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç–Ω—ã–π", "–ø–æ–∫—É–ø–∞–π—Ç–µ", "–ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å".
- –ù–µ —à—É—Ç–∏ –ø—Ä–æ –≤–æ—Å—Å—Ç–∞–Ω–∏–µ –º–∞—à–∏–Ω –∏ Skynet.
"""
    return prompt

def short_summary(title: str, summary: str, link: str) -> Optional[str]:
    prompt = build_dynamic_prompt(title, summary)
    print(f"  üìù –ì–µ–Ω–µ—Ä–∏—Ä—É—é –ø–æ—Å—Ç (Friendly AI Vibe)...")

    try:
        res = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7, 
            max_tokens=1000, # –î–∞–µ–º –º–æ–¥–µ–ª–∏ –º–µ—Å—Ç–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å—Å—è
        )
        core = res.choices[0].message.content.strip()

        if core.startswith('"') and core.endswith('"'): core = core[1:-1]
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–∫–ª–∞–º—É
        if is_too_promotional(core):
            print("  ‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º —Ä–µ–∫–ª–∞–º–Ω—ã–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
            return None

        topic = detect_topic(title, summary)
        hashtags = get_hashtags(topic)
        final = build_final_post(core, hashtags, link, max_total=TELEGRAM_CAPTION_LIMIT)
        return final

    except Exception as e:
        print(f"‚ùå OpenAI –æ—à–∏–±–∫–∞: {e}")
        return None

# ============ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–†–¢–ò–ù–û–ö (–ë–ï–ó –ö–ò–ë–ï–†–ü–ê–ù–ö–ê) ============

def generate_image(title: str, max_retries: int = 2) -> Optional[str]:
    # –°–ø–∏—Å–æ–∫ —Å–≤–µ—Ç–ª—ã—Ö, —á–∏—Å—Ç—ã—Ö —Å—Ç–∏–ª–µ–π (–ë–ï–ó –Ω–µ–æ–Ω–∞ –∏ –∫–∏–±–µ—Ä–ø–∞–Ω–∫–∞)
    styles = [
        "minimalist technology illustration, clean lines, white background, vector art, blue and white colors",
        "high tech laboratory, bright lighting, futuristic white robot arm, photorealistic, 4k",
        "abstract neural network visualization, connecting dots, blue and purple gradient, clean background",
        "isometric 3d icon of artificial intelligence, glass texture, soft studio lighting, blender render",
        "modern software interface concept, holograms, data visualization, bright modern office background"
    ]
    
    current_style = random.choice(styles)
    
    for attempt in range(max_retries):
        seed = random.randint(0, 10**7)
        clean_title = re.sub(r'[^a-zA-Z0-9]', ' ', title)[:60]
        
        # –ü—Ä–æ–º–ø—Ç –±–µ–∑ —Å–ª–æ–≤–∞ cyberpunk
        prompt = f"{current_style}, {clean_title}"
        
        encoded = urllib.parse.quote(prompt)
        url = f"https://image.pollinations.ai/prompt/{encoded}?seed={seed}&width=1024&height=1024&nologo=true"
        
        try:
            print(f"  üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ (—Å—Ç–∏–ª—å: {current_style[:20]})...")
            resp = requests.get(url, timeout=40, headers=HEADERS)
            if resp.status_code == 200 and len(resp.content) > 10000:
                fname = f"img_{seed}.jpg"
                with open(fname, "wb") as f: f.write(resp.content)
                return fname
        except Exception as e:
            print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏: {e}")
    return None

def cleanup_image(filepath: Optional[str]) -> None:
    if filepath and os.path.exists(filepath):
        try: os.remove(filepath)
        except: pass

# ============ –ê–í–¢–û–ü–û–°–¢ ============

async def autopost():
    clean_old_posts()
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π...")
    articles = load_articles_from_sites()
    
    # –°–¢–†–û–ì–ò–ô –§–ò–õ–¨–¢–†: –¢–æ–ª—å–∫–æ AI –Ω–æ–≤–æ—Å—Ç–∏
    candidates = filter_articles(articles)

    if not candidates:
        print("‚ùå –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –ø—Ä–æ AI.")
        return

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ: {len(candidates)} —Å—Ç–∞—Ç–µ–π –ø—Ä–æ AI.")
    
    # –ë–µ—Ä–µ–º —Å–∞–º—É—é —Å–≤–µ–∂—É—é –Ω–æ–≤–æ—Å—Ç—å
    art = candidates[0]

    print(f"\nüîç –û–±—Ä–∞–±–æ—Ç–∫–∞: {art['title']}")
    post_text = short_summary(art["title"], art["summary"], art["link"])

    if post_text:
        img = generate_image(art["title"])
        
        try:
            if img:
                await bot.send_photo(CHANNEL_ID, photo=FSInputFile(img), caption=post_text)
            else:
                await bot.send_message(CHANNEL_ID, text=post_text, disable_web_page_preview=False)

            save_posted(art["id"])
            print(f"‚úÖ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ!")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ TG: {e}")
        finally:
            cleanup_image(img)
    else:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç (–≤–æ–∑–º–æ–∂–Ω–æ, —Ñ–∏–ª—å—Ç—Ä —Ä–µ–∫–ª–∞–º—ã).")

async def main():
    try: await autopost()
    finally: await bot.session.close()

if __name__ == "__main__":
    asyncio.run(main())




















































































































































































































































