import os
import json
import asyncio
import random
from datetime import datetime
from typing import List, Dict, Optional

import requests
import feedparser
import urllib.parse
from aiogram import Bot
from aiogram.client.bot import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.types import FSInputFile
from openai import OpenAI

# ---------------- CONFIG ----------------

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")

if not all([OPENAI_API_KEY, TELEGRAM_BOT_TOKEN, CHANNEL_ID]):
    raise ValueError("‚ùå –ù–µ –≤—Å–µ ENV –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")

bot = Bot(
    token=TELEGRAM_BOT_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML),
)
openai_client = OpenAI(api_key=OPENAI_API_KEY)

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/120.0 Safari/537.36"
    )
}

POSTED_FILE = "posted_articles.json"
RETENTION_DAYS = 7

# ============ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê ============

REQUIRE_KEYWORDS = [
    # VPN, –ü—Ä–æ–∫—Å–∏, –¢—É–Ω–Ω–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
    "vpn", "–ø—Ä–æ–∫—Å–∏", "—Ç—É–Ω–Ω–µ–ª—å", "proxy", "tunnel",
    
    # –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ, –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, –ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å
    "—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ", "—à–∏—Ñ—Ä", "encrypt", "–ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å", "privacy",
    "–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "security", "–∑–∞—â–∏—Ç–∞ –¥–∞–Ω–Ω—ã—Ö",
    
    # –ò–Ω—Ç–µ—Ä–Ω–µ—Ç, –°–µ—Ç—å
    "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É", "internet", "—Å–µ—Ç—å",
    "—Å–µ—Ç–∏", "network", "–ø—Ä–æ—Ç–æ–∫–æ–ª", "protocol",
    
    # –ê–Ω–æ–Ω–∏–º–Ω–æ—Å—Ç—å, –°–∫—Ä—ã—Ç–∏–µ
    "–∞–Ω–æ–Ω–∏–º–Ω–æ—Å—Ç—å", "–∞–Ω–æ–Ω–∏–º–Ω—ã–π", "anonymous", "—Å–∫—Ä—ã—Ç–∏–µ", "—Å–∫—Ä—ã–≤–∞—Ç—å",
    "incognito", "—Å–∫—Ä—ã—Ç—ã–π", "hidden", "–º–∞—Å–∫–∏—Ä–æ–≤–∫–∞",
    
    # –¶–µ–Ω–∑—É—Ä–∞, –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏
    "—Ü–µ–Ω–∑—É—Ä–∞", "–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞", "–±–ª–æ–∫–∏—Ä–æ–≤", "–±–ª–æ–∫–∏—Ä", "blocking",
    "censorship", "restrict", "–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ", "–∑–∞–ø—Ä–µ—Ç",
    
    # DNS, DPI, –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    "dns", "dpi", "—Ñ–∏–ª—å—Ç—Ä", "filter", "—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è",
    
    # –û–±—Ö–æ–¥ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
    "–æ–±—Ö–æ–¥", "bypass", "circumvent", "–æ–±—Ö–æ–¥–∏—Ç—å", "–æ–±–æ–≥–Ω—É—Ç—å",
    
    # –†–æ—Å—Å–∏–π—Å–∫–∏–µ –æ—Ä–≥–∞–Ω—ã (–†–ö–ù, –ú–∏–Ω—Ü–∏—Ñ—Ä—ã, etc)
    "—Ä–æ—Å–∫–æ–º–Ω–∞–¥–∑–æ—Ä", "—Ä–∫–Ω", "–º–∏–Ω—Ü–∏—Ñ—Ä—ã", "–º–∏–Ω—Ü–∏—Ñ—Ä", "—Ñ–µ–¥—Å—É",
    "–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞", "—Ä–∞–∑–±–ª–æ–∫–∏—Ä", "–¥–µ–±–ª–æ–∫–∏—Ä",
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
    "—Ç—Ä–∞—Ñ–∏–∫", "traffic", "–ø–∞–∫–µ—Ç", "packet", "—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ",
    "connection", "–∫–∞–Ω–∞–ª", "channel", "–ª–∏–Ω–∏—è —Å–≤—è–∑–∏",
    "tor", "darknet", "darkweb", "–ª—É–∫–æ–≤–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è",
    "wireguard", "openvpn", "shadowsocks", "mtproto",
    "–æ–±—Ñ—É—Å–∫–∞—Ü–∏—è", "obfuscation", "–º–∞—Å–∫–∏—Ä–æ–≤–∫–∞ —Ç—Ä–∞—Ñ–∏–∫–∞",
    
    # –ù–µ–π—Ä–æ—Å–µ—Ç–∏ (–Ω–æ–≤–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ)
    "–Ω–µ–π—Ä–æ—Å–µ—Ç—å", "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏", "–∏–∏", "ai", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
    "llm", "gpt", "claude", "chatgpt",
]

# ============ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –†–û–°–°–ò–Ø ============
# –ù–û–í–û–°–¢–¨ –î–û–õ–ñ–ù–ê –°–û–î–ï–†–ñ–ê–¢–¨ –•–û–¢–Ø –ë–´ –û–î–ù–û –°–õ–û–í–û –û–¢–°–Æ–î–ê

RUSSIA_KEYWORDS = [
    "—Ä–æ—Å—Å–∏—è", "—Ä—Ñ", "—Ä—Ñ ", "—Ä–æ—Å—Å–∏–π—Å–∫", "—Ä–æ—Å—Å–∏–π",
    "–º–æ—Å–∫–≤", "–ø–∏—Ç–µ—Ä", "—Å–∞–Ω–∫—Ç", "—É—Ä–∞–ª", "—Å–∏–±–∏—Ä—å",
    "–∫—Ä—ã–º", "–¥–æ–Ω–µ—Ü–∫", "–ª—É–≥–∞–Ω—Å–∫", "–¥–Ω—Ä", "–ª–Ω—Ä",
]

# ============ –ò–°–ö–õ–Æ–ß–ò–¢–¨ ============

EXCLUDE_KEYWORDS = [
    # –°–ø–æ—Ä—Ç
    "—Ç–µ–Ω–Ω–∏—Å", "—Ñ—É—Ç–±–æ–ª", "—Ö–æ–∫–∫–µ–π", "–±–∞—Å–∫–µ—Ç–±–æ–ª", "–≤–æ–ª–µ–π–±–æ–ª",
    "—Å–ø–æ—Ä—Ç", "–æ–ª–∏–º–ø–∏–∞–¥", "—á–µ–º–ø–∏–æ–Ω–∞—Ç", "—Ç—É—Ä–Ω–∏—Ä", "–º–∞—Ç—á",
    "–∏–≥—Ä–æ–∫", "–∫–æ–º–∞–Ω–¥–∞", "–ª–∏–≥–∞", "—á–µ–º–ø–∏–æ–Ω",
    
    # –†–∞–∑–≤–ª–µ—á–µ–Ω–∏—è / –ò–≥—Ä—ã
    "–∏–≥—Ä–∞", "–≥–µ–π–º–ø–ª–µ–π", "gameplay", "dungeon", "quest",
    "playstation", "xbox", "nintendo", "steam", "boss", "raid",
    "—à—É—Ç–µ—Ä", "mmorpg", "battle royale", "–≥–µ–π–º–µ—Ä", "gamer",
    "helldivers", "routine", "–∏–≥—Ä–æ–≤–æ–π", "–∏–≥—Ä–æ–≤—ã—Ö",
    
    # –õ–∏—á–Ω–æ–µ / –ë–ª–æ–≥
    "–º–æ—è –∂–∏–∑–Ω—å", "–º–æ–π –æ–ø—ã—Ç", "–∫–∞–∫ —è", "–º–æ—è –∏—Å—Ç–æ—Ä–∏—è",
    "–≤–µ—Ä–Ω—É–ª—Å—è", "–≤–µ—Ä–Ω—É–ª–∞—Å—å", "–ª–∏—á–Ω—ã–π –æ–ø—ã—Ç", "—è –¥–µ–ª–∞—é",
    
    # –ö–∏–Ω–æ, –¢–í, –ú—É–∑—ã–∫–∞
    "–∫–∏–Ω–æ", "—Ñ–∏–ª—å–º", "—Å–µ—Ä–∏–∞–ª", "–º—É–∑—ã–∫–∞", "–∫–æ–Ω—Ü–µ—Ä—Ç",
    "–∞–∫—Ç–µ—Ä", "—Ä–µ–∂–∏—Å—Å–µ—Ä", "–ø–µ—Å–Ω—è", "–∫–ª–∏–ø", "–≤–∏–¥–µ–æ–∫–ª–∏–ø",
    "–¥–∞–π–¥–∂–µ—Å—Ç", "digest", "–æ–±–∑–æ—Ä –∏–≥—Ä", "–Ω–æ–≤–æ—Å—Ç–∏ –∏–≥—Ä",
    "–ø—Ä–µ–º—å–µ—Ä–∞", "–≤—ã–ø—É—Å–∫ —Å–µ–∑–æ–Ω–∞",
    
    # –ö–æ—Ä–ø–æ—Ä–∞—Ü–∏–∏ / –§–∏–Ω–∞–Ω—Å—ã
    "coca-cola", "pepsi", "nestle", "tesla",
    "samsung", "sony", "lg", "huawei",
    "–∫–æ–º–ø–∞–Ω–∏—è —Å–æ–æ–±—â–∏–ª–∞", "–∫–æ–º–ø–∞–Ω–∏—è –æ–±—ä—è–≤–∏–ª–∞",
    "–∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è", "–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π",
    "–∞–∫—Ü–∏–∏", "–±–∏—Ä–∂–∞", "–∏–Ω–≤–µ—Å—Ç–æ—Ä", "–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è",
    "–≤—ã—Ä—É—á–∫–∞", "–ø—Ä–∏–±—ã–ª—å", "—É–±—ã—Ç–æ–∫", "–¥–æ—Ö–æ–¥", "–æ–±–æ—Ä–æ—Ç",
    "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", "—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –æ—Ç—á–µ—Ç",
    "–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å", "–∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç", "–≥–æ–¥–æ–≤–æ–π –æ—Ç—á–µ—Ç",
    "–≥–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä", "ceo", "cfo",
    "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "–±—Ä–µ–Ω–¥", "—Ä–µ–∫–ª–∞–º–∞", "–∫–∞–º–ø–∞–Ω–∏—è",
    "–ª–æ–Ω—á –ø—Ä–æ–¥—É–∫—Ç–∞", "–≤—ã—Ö–æ–¥ –ø—Ä–æ–¥—É–∫—Ç–∞", "–Ω–æ–≤—ã–π –ø—Ä–æ–¥—É–∫—Ç",
    
    # –ü–æ–ª–∏—Ç–∏–∫–∞ (–≤ –æ–±—â–µ–º)
    "–≤—ã–±–æ—Ä—ã", "–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç", "–ø–∞—Ä–ª–∞–º–µ–Ω—Ç", "–∑–∞–∫–æ–Ω",
    "–ø–æ–ª–∏—Ç–∏–∫", "–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫", "–ø–∞—Ä—Ç–∏—è",
    
    # –ú–µ–¥–∏—Ü–∏–Ω–∞ / –ó–¥–æ—Ä–æ–≤—å–µ
    "–±–æ–ª–µ–∑–Ω—å", "–∑–∞–±–æ–ª–µ–≤–∞", "–≤–∏—Ä—É—Å", "covid", "–∫–æ—Ä–æ–Ω–∞–≤–∏—Ä—É—Å",
    "–ª–µ–∫–∞—Ä—Å—Ç–≤–æ", "—Ç–∞–±–ª–µ—Ç–∫–∞", "—Ç–µ—Ä–∞–ø–∏—è", "–ª–µ—á–µ–Ω–∏–µ",
    
    # –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞
    "–±–∏—Ç–∫–æ–π–Ω", "bitcoin", "—ç—Ñ–∏—Ä–∏—É–º", "ethereum",
    "–∫—Ä–∏–ø—Ç–æ", "crypto", "–±–ª–æ–∫—á–µ–π–Ω", "blockchain",
    
    # –ê–≤—Ç–æ–º–æ–±–∏–ª–∏
    "–∞–≤—Ç–æ–º–æ–±–∏–ª—å", "–º–∞—à–∏–Ω–∞", "–∞–≤—Ç–æ", "car",
    "–¥–≤–∏–≥–∞—Ç–µ–ª—å", "–º–æ—Ç–æ—Ä", "–±–µ–Ω–∑–∏–Ω", "–≥–∞–∑",
    
    # –°—É–¥–µ–±–Ω—ã–µ –¥–µ–ª–∞ (–µ—Å–ª–∏ –Ω–µ –ø—Ä–æ –†–§ –∏ —Ü–µ–Ω–∑—É—Ä—É)
    "—Å—É–¥", "—Å—É–¥–µ–±–Ω—ã–π", "—Å—É–¥—å—è", "–∞–ø–µ–ª–ª—è—Ü–∏—è", "–∏—Å–∫",
    "–∞–≤—Å—Ç—Ä–∞–ª–∏—è", "–∞–≤—Å—Ç—Ä–∞–ª–∏–π—Å–∫–∏–π", "–Ω–æ–≤–∞—è –∑–µ–ª–∞–Ω–¥–∏—è",
    "–≤–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è", "–∞–Ω–≥–ª–∏—è", "–∫–∞–Ω–∞–¥–∞",
    
    # –°–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏ (–µ—Å–ª–∏ –Ω–µ –ø—Ä–æ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É)
    "reddit", "twitter", "instagram", "tiktok",
    "facebook", "youtube ban",
    
    # –ü—Ä–æ—á–µ–µ
    "–ø–æ–ª–Ω–æ–ª—É–Ω–∏–µ", "–∞—Å—Ç—Ä–æ–Ω–æ–º–∏—è", "–∫–æ—Å–º–æ—Å",
    "–ø–æ–≥–æ–¥–∞", "–∫–ª–∏–º–∞—Ç", "—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
    "–∂–∏–≤–æ—Ç–Ω–æ–µ", "–∂–∏–≤–æ—Ç–Ω—ã—Ö", "–ø–∏—Ç–æ–º–µ—Ü", "—Å–æ–±–∞–∫–∞", "–∫–æ—à–∫–∞",
    "–µ–¥–∞", "—Ä–µ—Ü–µ–ø—Ç", "–∫—É—Ö–Ω—è", "–∫—É–ª–∏–Ω–∞—Ä",
    "–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–µ", "—Ç—É—Ä–∏–∑–º", "–æ—Ç–ø—É—Å–∫",
]

# ---------------- STATE ----------------

if os.path.exists(POSTED_FILE):
    with open(POSTED_FILE, "r", encoding="utf-8") as f:
        try:
            posted_data = json.load(f)
            if isinstance(posted_data, list) and posted_data and isinstance(posted_data[0], dict):
                posted_articles = {item["id"]: item.get("timestamp") for item in posted_data}
            else:
                posted_articles = {id_str: None for id_str in posted_data}
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            posted_articles = {}
else:
    posted_articles = {}

def save_posted_articles() -> None:
    try:
        data = [{"id": id_str, "timestamp": ts} for id_str, ts in posted_articles.items()]
        with open(POSTED_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")

def clean_old_posts() -> None:
    global posted_articles
    now = datetime.now().timestamp()
    cutoff = now - (RETENTION_DAYS * 86400)
    old_count = len(posted_articles)
    posted_articles = {
        id_str: ts for id_str, ts in posted_articles.items()
        if ts is None or ts > cutoff
    }
    removed = old_count - len(posted_articles)
    if removed > 0:
        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –ø–æ—Å—Ç–æ–≤: {removed}")
    save_posted_articles()

def save_posted(article_id: str) -> None:
    posted_articles[article_id] = datetime.now().timestamp()
    save_posted_articles()

# ---------------- HELPERS ----------------

def safe_get(url: str) -> Optional[str]:
    try:
        resp = requests.get(url, headers=HEADERS, timeout=15)
        if resp.status_code != 200:
            return None
        return resp.text
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ {url}: {e}")
        return None

def clean_text(text: str) -> str:
    return " ".join(text.replace("\n", " ").replace("\r", " ").split())

# ---------------- PARSERS (3 –°–ê–ô–¢–ê) ----------------

def load_3dnews() -> List[Dict]:
    try:
        html = safe_get("https://3dnews.ru/")
        if not html:
            return []

        articles = []
        parts = html.split('<a href="/')

        for part in parts[1:15]:
            try:
                href_end = part.find('"')
                title_start = part.find(">")
                title_end = part.find("</a>")
                if href_end == -1 or title_start == -1 or title_end == -1:
                    continue

                href = part[:href_end]
                title = clean_text(part[title_start + 1:title_end])
                if not title:
                    continue

                link = "https://3dnews.ru/" + href.lstrip("/")
                summary = ""

                desc_start = part.find('class="')
                if desc_start != -1:
                    desc_chunk = part[desc_start:desc_start + 700]
                    p_start = desc_chunk.find(">")
                    if p_start != -1:
                        p_end = desc_chunk.find("</", p_start)
                        if p_end != -1:
                            summary = clean_text(desc_chunk[p_start + 1:p_end])[:700]

                articles.append({
                    "id": link,
                    "title": title,
                    "summary": summary,
                    "link": link,
                    "source": "3DNews",
                    "published_parsed": datetime.now(),
                })
            except Exception:
                continue

        return articles
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ 3DNews: {e}")
        return []

def load_rss(url: str, source: str) -> List[Dict]:
    articles = []
    try:
        feed = feedparser.parse(url)
        for entry in feed.entries[:50]:
            try:
                link = entry.get("link", "")
                title = clean_text(entry.get("title") or "")
                summary = clean_text(
                    entry.get("summary") or entry.get("description") or ""
                )[:700]
                if not link or not title:
                    continue

                published_parsed = datetime.now()
                if hasattr(entry, "published_parsed") and entry.published_parsed:
                    try:
                        published_parsed = datetime(*entry.published_parsed[:6])
                    except Exception:
                        pass

                articles.append({
                    "id": link,
                    "title": title,
                    "summary": summary,
                    "link": link,
                    "source": source,
                    "published_parsed": published_parsed,
                })
            except Exception:
                continue
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ RSS {url}: {e}")
    return articles

def load_articles_from_sites() -> List[Dict]:
    articles = []
    articles.extend(load_3dnews())
    articles.extend(load_rss("https://vc.ru/rss", "VC.ru"))
    articles.extend(load_rss("https://xakep.ru/feed/", "Xakep.ru"))
    print(f"–í–°–ï–ì–û: {len(articles)} —Å—Ç–∞—Ç–µ–π –¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
    return articles

# ============ –§–ò–õ–¨–¢–†–ê–¶–ò–Ø ============

def check_require_keywords(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω REQUIRE –∫–ª—é—á."""
    text_lower = text.lower()
    return any(kw in text_lower for kw in REQUIRE_KEYWORDS)

def check_exclude_keywords(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ EXCLUDE –∫–ª—é—á–∏ ‚Äî –µ—Å–ª–∏ –µ—Å—Ç—å, –æ—Ç—Å–µ–∏–≤–∞–µ–º."""
    text_lower = text.lower()
    return any(kw in text_lower for kw in EXCLUDE_KEYWORDS)

def has_russia_mention(text: str) -> bool:
    """–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û: –≤ –Ω–æ–≤–æ—Å—Ç–∏ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –†–û–°–°–ò–Ø."""
    text_lower = text.lower()
    return any(kw in text_lower for kw in RUSSIA_KEYWORDS)

# ============ –í–´–ë–û–† –°–¢–ê–¢–¨–ò ============

def pick_article(articles: List[Dict]) -> Optional[Dict]:
    suitable_articles: List[Dict] = []
    skipped = 0
    excluded_require = 0
    excluded_blacklist = 0
    excluded_no_russia = 0

    for e in articles:
        aid = e.get("id")
        if aid in posted_articles:
            skipped += 1
            continue

        title = e.get("title", "")
        summary = e.get("summary", "")
        text = f"{title} {summary}"

        # –®–ê–ì 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        if check_exclude_keywords(text):
            excluded_blacklist += 1
            continue

        # –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π
        if not check_require_keywords(text):
            excluded_require += 1
            continue

        # –®–ê–ì 3: –°–¢–†–û–ì–û –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û - –†–û–°–°–ò–Ø –í –¢–ï–ö–°–¢–ï
        if not has_russia_mention(text):
            excluded_no_russia += 1
            continue

        # ‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
        suitable_articles.append(e)
        print(f"  ‚úÖ –ü–æ–¥—Ö–æ–¥–∏—Ç: {title[:70]}")

    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:")
    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –±—ã–ª–∏): {skipped}")
    print(f"  –ò—Å–∫–ª—é—á–µ–Ω–æ (—á—ë—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫): {excluded_blacklist}")
    print(f"  –ò—Å–∫–ª—é—á–µ–Ω–æ (–Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π): {excluded_require}")
    print(f"  –ò—Å–∫–ª—é—á–µ–Ω–æ (–ù–ï–¢ –†–û–°–°–ò–ò –≤ —Ç–µ–∫—Å—Ç–µ): {excluded_no_russia}")
    print(f"  –ü–æ–¥—Ö–æ–¥—è—Ç (–í–°–ï —É—Å–ª–æ–≤–∏—è): {len(suitable_articles)}")

    if not suitable_articles:
        print("‚ùå –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –ø—Ä–æ –†–æ—Å—Å–∏—é!")
        return None

    suitable_articles.sort(
        key=lambda x: x.get("published_parsed", datetime.now()),
        reverse=True
    )
    chosen = suitable_articles[0]
    print(f"\nüéØ –í—ã–±—Ä–∞–Ω–∞: {chosen['title'][:80]}")
    return chosen

# ============ OPENAI TEXT ============

def short_summary(title: str, summary: str, link: str) -> str:
    news_text = f"{title}. {summary}" if summary else title
    prompt = (
        "–í–æ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç –Ω–æ–≤–æ—Å—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–∏. –°–æ—Ö—Ä–∞–Ω–∏ —Ñ–∞–∫—Ç—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±–ª–∏–∑–∫–æ –∫ —Ç–µ–∫—Å—Ç—É, "
        "–ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π —Ç–æ–ª—å–∫–æ —á—Ç–æ–±—ã —á–∏—Ç–∞–ª–æ—Å—å –ø–ª–∞–≤–Ω–æ.\n\n"
        f"{news_text}\n\n"
        "–°–¥–µ–ª–∞–π –∫–æ—Ä–æ—Ç–∫–∏–π –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –ø–æ—Å—Ç –¥–ª—è Telegram:\n"
        "- –û–±—ä—ë–º —Å—Ç—Ä–æ–≥–æ 450‚Äì550 —Å–∏–º–≤–æ–ª–æ–≤.\n"
        "- –£–¥–∞–ª–∏ –≤—Å—ë, —á—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ —Ä–µ–∫–ª–∞–º—É, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –ø—Ä–æ–º–æ.\n"
        "- –ù–∏–∫–∞–∫–∏—Ö –≤—ã–¥—É–º–∞–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π, —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –µ—Å—Ç—å –≤ —Ç–µ–∫—Å—Ç–µ.\n"
        "- –í –∫–æ–Ω—Ü–µ 2‚Äì3 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ö–µ—à—Ç–µ–≥–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª.\n"
        "- 1‚Äì2 —ç–º–æ–¥–∑–∏ –ø–æ —Å–º—ã—Å–ª—É –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞.\n"
        "- –ù–µ –¥–æ–±–∞–≤–ª—è–π –ø—Ä–∏–∑—ã–≤ –Ω–∞ –ø–æ–¥–ø–∏—Å–∫—É –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ –∫–∞–Ω–∞–ª."
    )

    try:
        res = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=320,
        )
        text = res.choices[0].message.content.strip()

        if len(text) > 550:
            print(f"‚ö†Ô∏è –¢–µ–∫—Å—Ç {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, —Ä–µ–∂—É –¥–æ 550")
            text = text[:547] + "‚Ä¶"

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –∏ PS
        ps = f"\n\nüîó –û—Ä–∏–≥–∏–Ω–∞–ª: {link}\n\nPSüí• –ö—Ç–æ –∑–∞ –∫–ª—é—á–∞–º–∏ üëâ https://t.me/+EdEfIkn83Wg3ZTE6"
        full_text = text + ps

        if len(full_text) > 1020:
            excess = len(full_text) - 1020
            text = text[:-(excess + 3)] + "‚Ä¶"
            full_text = text + ps

        print(f"üìä –ò—Ç–æ–≥–æ–≤–∞—è –¥–ª–∏–Ω–∞: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        return full_text

    except Exception as e:
        print(f"‚ùå OpenAI: {e}")
        fallback = f"{title}\n\n{(summary or '')[:400]}"
        return f"{fallback}\n\nüîó {link}\n\nPSüí• –ö—Ç–æ –∑–∞ –∫–ª—é—á–∞–º–∏ üëâ https://t.me/+EdEfIkn83Wg3ZTE6"

# ============ –ö–ê–†–¢–ò–ù–ö–ò (POLLINATIONS - –ë–ï–°–ü–õ–ê–¢–ù–û) ============

def generate_image(title: str) -> Optional[str]:
    """
    –ö–∞—Ä—Ç–∏–Ω–∫–∞ —á–µ—Ä–µ–∑ Pollinations (–±–µ—Å–ø–ª–∞—Ç–Ω–æ).
    –ö–∞–∂–¥—ã–π —Ä–∞–∑ –Ω–æ–≤—ã–π seed, —á—Ç–æ–±—ã –∫–∞—Ä—Ç–∏–Ω–∫–∏ –±—ã–ª–∏ —Ä–∞–∑–Ω—ã–µ.
    """
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    seed = random.randint(0, 10_000_000)

    prompt_core = (
        f"realistic cinematic detailed illustration about {title[:100]}, "
        "modern cybersecurity and internet privacy, people using computers, "
        "daytime city or office, neutral natural colors, soft light, high detail, 4k, "
        "photo realistic, professional editorial photography, not cartoon, not anime. "
        "no cyberpunk, no neon lights, no sci-fi, no futuristic helmets, "
        "no glowing effects, no dystopia, no text, no logo, no watermark"
    )

    # –î–æ–±–∞–≤–ª—è–µ–º noise –≤ –ø—Ä–æ–º–ø—Ç, —á—Ç–æ–±—ã –ª–æ–º–∞—Ç—å HTTP-–∫—ç—à
    prompt = prompt_core + f" random detail id {seed}"

    print("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pollinations")
    print(f"   Seed: {seed}")

    try:
        encoded = urllib.parse.quote(prompt)
        url = f"https://image.pollinations.ai/prompt/{encoded}?seed={seed}"

        resp = requests.get(url, timeout=120)
        if resp.status_code != 200:
            print(f"‚ùå Pollinations HTTP {resp.status_code}")
            return None

        filename = f"news_{timestamp}_{random.randint(1000,9999)}.jpg"
        with open(filename, "wb") as f:
            f.write(resp.content)

        print(f"‚úÖ –ö–∞—Ä—Ç–∏–Ω–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filename}")
        return filename

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Pollinations: {e}")
        return None

# ============ –ê–í–¢–û–ü–û–°–¢ ============

async def autopost():
    clean_old_posts()
    articles = load_articles_from_sites()
    if not articles:
        print("–ù–µ—Ç —Å—Ç–∞—Ç–µ–π")
        return

    art = pick_article(articles)
    if not art:
        print("–ù–µ—Ç —Å—Ç–∞—Ç–µ–π –ø—Ä–æ –†–æ—Å—Å–∏—é —Å –Ω—É–∂–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏")
        return

    aid = art["id"]
    print(f"\n‚úÖ –í—ã–±—Ä–∞–Ω–∞: {art['title']}")
    print(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {art['source']}\n")

    try:
        text = short_summary(art["title"], art.get("summary", ""), art.get("link", ""))
        img_file = generate_image(art["title"])

        if img_file and os.path.exists(img_file):
            await bot.send_photo(
                chat_id=CHANNEL_ID,
                photo=FSInputFile(img_file),
                caption=text,
            )
            os.remove(img_file)
            print("‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π")
        else:
            await bot.send_message(
                chat_id=CHANNEL_ID,
                text=text,
            )
            print("‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–º (–±–µ–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏)")

        save_posted(aid)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")

async def main():
    try:
        await autopost()
    finally:
        await bot.session.close()

if __name__ == "__main__":
    asyncio.run(main())
























































































